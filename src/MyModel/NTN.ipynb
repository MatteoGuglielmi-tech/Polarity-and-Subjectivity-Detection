{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXXx62MhlOvIgvkghCLoPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/src/MyModel/NTN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NTN (Neural Tensor Network) [[reference_paper](https://proceedings.neurips.cc/paper/2013/file/b337e84de8752b27eda3a12363109e80-Paper.pdf)]\n",
        "\n",
        "<u><i>Goal</i></u> : state if two entities $(e_1, e_2)$ are in a certain relationship $R$.   \n",
        ">Ex. defines whehter $$(e_1, R, e_2) = (\\text{Bengal tiger}, \\text{has part}, \\text{tail})$$ is true and with which certainty.\n",
        "\n",
        "- $e_1$ and $e_2$ are vector representations or features of the two entities.\n",
        "- NTN, unlike a linear canoncical NN layer, uses a bilinear tensor layer that directly relates two entity vectors across differet dimensions.\n",
        "- Model computes a score of how likely it is two entities are in a specific position following : $$g(e_1, R, e_2) = u_R^Tf\\biggr(e_i^T W_R^{[1:K]}e_2+V_R \\begin{align}\n",
        "    \\begin{bmatrix}\n",
        "           e_{1} \\\\\n",
        "           e_{2} \\\\\n",
        "         \\end{bmatrix}\n",
        "  \\end{align} + b_R\\Biggl)$$  \n",
        "where : \n",
        "- $f=\\tanh$\n",
        "- $W_R^{[1:K]} \\in \\mathbb{R}^{d\\times d\\times k}$ is a multi-dimensional tensor\n",
        "- $e_1^TW_R^{[1:k]}e_2=h\\in\\mathbb{R}$ is the bilinear tensor\n",
        "- $V_R \\in \\mathbb{R}^{k\\times2d}$, $U \\in \\mathbb{R}^K$, $b_R\\in \\mathbb{R}^K$ are NN parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KuB3DKrgQfSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### pytorch trials"
      ],
      "metadata": {
        "id": "Tq-h_R_lEKwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4WlxO-pC-Pmo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralTensorNetwork(nn.Module):\n",
        "    def __init__(self, output_dim: int, input_dim: int, activation: str=\"tanh\", mean: float=0.0, std: float=1.0):\n",
        "        \n",
        "        super(NeuralTensorNetwork, self).__init__()\n",
        "\n",
        "        # setting input and output dimensions\n",
        "        self.k = output_dim\n",
        "        self.d = input_dim # e1,e2\n",
        "\n",
        "        # setting mean and std for random initialization\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "        # parameters has been used in order to consider W, V, b as model parameters\n",
        "        # inference -> they'll be optimized\n",
        "\n",
        "        # normal sampling -> https://pytorch.org/docs/stable/generated/torch.normal.html\n",
        "        # parameter -> https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter\n",
        "        self.W = nn.Parameter(torch.normal(self.mean, self.std, size=(self.k, self.d, self.d)))\n",
        "        self.V = nn.Parameter(torch.normal(self.mean, self.std, size=(2*self.d, self.k)))\n",
        "        self.b = nn.Parameter(torch.zeros(size=(self.d,)))\n",
        "        \n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif self.activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        # checking for a good activation function\n",
        "        else:\n",
        "            raise ValueError('Possible activation choices are tanh, sigmoid or ReLU')\n",
        "\n",
        "    def forward(self, inputs: Tuple[torch.Tensor, torch.Tensor]):\n",
        "\n",
        "        # getting the entities\n",
        "        e1 = inputs[0]\n",
        "        e2 = inputs[1]\n",
        "\n",
        "        # input tensor should be of shape (batch_size, padded_length, 768)\n",
        "        batch_size = e1[0]\n",
        "        k = self.k\n",
        "        d = self.d\n",
        "\n",
        "        # bilinear tensor + bias\n",
        "        bil_bias = [torch.sum((e2 * torch.dot(e1, self.W[0])) + self.b, axis=1)]\n",
        "        for i in range(1,k):\n",
        "            bil_bias.append(torch.sum((e2*torch.dot(e1, self.W[i]))) + self.b, axis=1)\n",
        "        bil_bias = torch.reshape(torch.cat(bil_bias, axis=0), (batch_size, k))\n",
        "\n",
        "        # Vr * [e1, e2]\n",
        "        rest = torch.dot(torch.cat([e1,e2]), self.V)\n",
        "\n",
        "        e1_R_e2 = bil_bias + rest\n",
        "\n",
        "        # applying activation\n",
        "        f = self.activation(e1_R_e2)\n",
        "        return f"
      ],
      "metadata": {
        "id": "-anTmLwuTLvR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batching_data(data: Tuple[np.array, np.array], batch_size: int=64) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
        "    x1 = DataLoader(dataset=data, sampler=RandomSampler(data), batch_size=64, shuffle=False)\n",
        "    #x2 = DataLoader(dataset=data[1], sampler=RandomSampler(data[1]), batch_size=64, shuffle=False)\n",
        "    return x1#, x2 "
      ],
      "metadata": {
        "id": "FtBwT8k8z-89"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Dummy training data\n",
        "x_train1 = np.random.random((1000, 300))\n",
        "x_train2 = np.random.random((1000, 300))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Dummy validation data\n",
        "x_val1 = np.random.random((100, 300))\n",
        "x_val2 = np.random.random((100, 300))\n",
        "y_val = np.random.random((100, 1))\n",
        "\n",
        "\n",
        "print ('Shape of Training Data: ', x_train1.shape, x_train2.shape, y_train.shape)\n",
        "print ('Shape of Validation Data', x_val1.shape, x_val2.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "TXq4IXC-pYRW",
        "outputId": "b48f26e3-dd34-4699-f41d-4fd412c70c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:  (1000, 300) (1000, 300) (1000, 1)\n",
            "Shape of Validation Data (100, 300) (100, 300) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2 = batching_data([x_train1, x_train2])"
      ],
      "metadata": {
        "id": "7xvVymYO2uAk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlE35uqf7ItV",
        "outputId": "d207aaa8-0855-460b-a696-d518aa71506a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FgpHwh97N1N",
        "outputId": "a3c33fdc-9f83-4248-9e3e-aa8725c1992b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mse() -> torch.nn.MSELoss:\n",
        "    return nn.MSELoss()"
      ],
      "metadata": {
        "id": "MoLLwKrUpo2E"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(model, lr):\n",
        "    return torch.optim.Adam(model.parameters(), lr)"
      ],
      "metadata": {
        "id": "Kygj0APpqNMy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    bilinear : NeuralTensorNetwork(output_dim=32, input_dim=300, activation='relu')\n",
        "    g : nn.Linear(in_features=32, out_features=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        bilinear = bilinear(x)\n",
        "        dense = g(bilinear)\n",
        "\n",
        "        return dense\n"
      ],
      "metadata": {
        "id": "oXYJHYFm_Fqr"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, data, optimizer, cf, targets, device='cuda'):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "    cumulative_accuracy = 0.\n",
        "  \n",
        "    model.train() \n",
        " \n",
        "    # iterate over the training set\n",
        "    for batch_idx, inputs in enumerate(data):\n",
        "        # load data into GPU\n",
        "        input1 = inputs[0].to(device)\n",
        "        input2 = inputs[1].to(device)\n",
        "        inputs = [input1, input2]\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # loss computation\n",
        "        loss = get_mse(outputs, targets)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "    \n",
        "        # parameters update\n",
        "        optimizer.step()\n",
        "\n",
        "        # gradients reset\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # fetch prediction and loss value\n",
        "        samples += inputs.shape[0]\n",
        "        cumulative_loss += loss.item()\n",
        "        _, predicted = outputs.max(dim=1) # max() returns (maximum_value, index_of_maximum_value)\n",
        "\n",
        "        # compute training accuracy\n",
        "        cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "UWog0GYEq7fD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    model = NeuralTensorNetwork(output_dim=32, input_dim=300, activation='relu').to('cuda')\n",
        "    optimizer = get_optimizer(model, 0.001)\n",
        "    loss = get_mse()\n",
        "\n",
        "    data = batching_data([x_train1, x_train2])\n",
        "\n",
        "    for e in range(0,5):\n",
        "        train_loss, train_accuracy = training_step(model, data, optimizer, loss, y_train, 'cuda')\n",
        "        print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n"
      ],
      "metadata": {
        "id": "hPV92aDducGF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "3yg72_9i1BSk",
        "outputId": "104d7a3a-b72d-4852-d68a-584ee00b6d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-489d983485c9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-66743d9c4e04>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, data, optimizer, cf, targets, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# load data into GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensrflow Version"
      ],
      "metadata": {
        "id": "XYzKkf7VEREB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K  # in keras simple computations are not handled directly but it relies on a well optimized tensor handler library\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "2zWIRcpstrr1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralTensorLayer(Layer):\n",
        "    def __init__(self, output_dim, input_dim, activation= None):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim #The k in the formula\n",
        "        self.input_dim = input_dim   #The d in the formula\n",
        "        self.activation = activation #The f function in the formula\n",
        "        \n",
        "    # called the first time call is called\n",
        "    def build(self, input_shape):\n",
        "        #The initialisation parameters\n",
        "        self.mean = 0.0 \n",
        "        self.stddev = 1.0\n",
        "        dtype = 'float32'\n",
        "        self.seed = 1\n",
        "        \n",
        "        #The output and the inut dimension\n",
        "        k = self.output_dim\n",
        "        d = self.input_dim\n",
        "        \n",
        "        #Initialise the variables to be trained. The variables are according to the\n",
        "        #function defined.\n",
        "        self.W = K.variable(K.random_normal((k,d,d), self.mean, self.stddev,\n",
        "                               dtype=dtype, seed=self.seed))\n",
        "        self.V = K.variable(K.random_normal((2*d,k), self.mean, self.stddev,\n",
        "                               dtype=dtype, seed=self.seed))\n",
        "        self.b = K.zeros((self.input_dim,))\n",
        "        \n",
        "        #Set the variables to be trained.\n",
        "        self._trainable_weights = [self.W, self.V, self.b]\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        #Get Both the inputs\n",
        "        e1 = inputs[0]\n",
        "        e2 = inputs[1]\n",
        "\n",
        "        #Get the batch size\n",
        "        batch_size = K.shape(e1)[0]\n",
        "        \n",
        "        #The output and the inut dimension\n",
        "        k = self.output_dim\n",
        "        d = self.input_dim\n",
        "\n",
        "        #The first term in the function which is the bilinear product is calculated here.\n",
        "        first_term_k = [K.sum((e2 * K.dot(e1, self.W[0])) + self.b, axis=1)]\n",
        "        for i in range(1, k):\n",
        "            temp = K.sum((e2 * K.dot(e1, self.W[i])) + self.b, axis=1)\n",
        "            first_term_k.append(temp)\n",
        "        first_term = K.reshape(K.concatenate(first_term_k, axis=0), (batch_size, k))\n",
        "\n",
        "        #The second term in the function is calculated here.\n",
        "        second_term = K.dot(K.concatenate([e1,e2]), self.V)\n",
        "        \n",
        "        #Sum of the two terms to get the final function\n",
        "        z =  first_term + second_term\n",
        " \n",
        "        # The activation is selected here\n",
        "        if (self.activation == None):\n",
        "            return z\n",
        "        elif (self.activation == 'tanh'):\n",
        "            return K.tanh(z)\n",
        "        elif (self.activation == 'relu'):\n",
        "            return K.relu(z)\n",
        "        else :\n",
        "            print ('Activation not found')"
      ],
      "metadata": {
        "id": "7c9WtJoGtl1b"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Dummy training data\n",
        "x_train1 = np.random.random((1000, 300))\n",
        "x_train2 = np.random.random((1000, 300))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Dummy validation data\n",
        "x_val1 = np.random.random((100, 300))\n",
        "x_val2 = np.random.random((100, 300))\n",
        "y_val = np.random.random((100, 1))\n",
        "\n",
        "print ('Shape of Training Data: ', x_train1.shape, x_train2.shape, y_train.shape)\n",
        "print ('Shape of Validation Data', x_val1.shape, x_val2.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxiWrtEXuoJ7",
        "outputId": "900ab049-5388-424e-e004-e791395db86f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:  (1000, 300) (1000, 300) (1000, 1)\n",
            "Shape of Validation Data (100, 300) (100, 300) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here Define the model\n",
        "vector1 = Input(shape=(300,), dtype='float32')\n",
        "vector2 = Input(shape=(300,), dtype='float32')\n",
        "BilinearLayer = NeuralTensorLayer(output_dim=32, input_dim=300, \n",
        "                                  activation= 'relu')([vector1, vector2])\n",
        "\n",
        "g = Dense(1)(BilinearLayer)\n",
        "\n",
        "#The g or the output of the modelled function.\n",
        "model = Model(inputs=[vector1, vector2], outputs=[g])\n",
        "\n",
        "#Compile the model\n",
        "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "#The summary of the model.\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssnK68owuovX",
        "outputId": "b1a44a02-7fe3-4cf5-b784-427c1da32dfc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_25 (InputLayer)          [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)          [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " neural_tensor_layer_12 (Neural  (None, 32)          2899500     ['input_25[0][0]',               \n",
            " TensorLayer)                                                     'input_26[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 1)            33          ['neural_tensor_layer_12[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,899,533\n",
            "Trainable params: 2,899,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([x_train1, x_train2], y_train,\n",
        "          batch_size=64, epochs=10,\n",
        "          validation_data=([x_val1, x_val2], y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uGv2VC0uz_k",
        "outputId": "4616c55b-edbf-4a9c-809a-4b938d7a1425"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 36s - loss: 24450.2891<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 14604.1045 <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 9383.4521 <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 6751.2588<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 5258.8823<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 4403.5122<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 3s 51ms/step - loss: 4403.5122 - val_loss: 132.9232\n",
            "Epoch 2/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 65.1620<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 62.0816<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 58.3054<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 48.9747<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 41.3661<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 36.2625<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 36.2625 - val_loss: 44.8223\n",
            "Epoch 3/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 13.4534<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 13.2699<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 10.1565<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 9.7253 <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 8.6971<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 9.5897<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 9.5897 - val_loss: 28.1073\n",
            "Epoch 4/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 3.9056<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 3/16 [====>.........................] - ETA: 0s - loss: 6.9934<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 6/16 [==========>...................] - ETA: 0s - loss: 4.4082<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 9/16 [===============>..............] - ETA: 0s - loss: 6.0005<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "12/16 [=====================>........] - ETA: 0s - loss: 5.8506<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 5.5852<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 5.5340 - val_loss: 22.8900\n",
            "Epoch 5/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 4.5913<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 5.2036<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 4.2123<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 6.0989<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 6.1510<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 7.0430<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 7.0430 - val_loss: 20.3024\n",
            "Epoch 6/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 5.0276<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 5.6679<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 7.2339<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 5.7560<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 6.6181<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 6.2029<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 6.2029 - val_loss: 18.2121\n",
            "Epoch 7/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 4.4335<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 7.3136<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 10.1808<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 8.0365 <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 7.6787<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 6.6842<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 6.6842 - val_loss: 16.3095\n",
            "Epoch 8/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 0.8012<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 3/16 [====>.........................] - ETA: 0s - loss: 2.2539<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 6/16 [==========>...................] - ETA: 0s - loss: 3.2661<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 9/16 [===============>..............] - ETA: 0s - loss: 3.9675<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "12/16 [=====================>........] - ETA: 0s - loss: 3.6925<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 3.4352<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 3.5267 - val_loss: 14.9691\n",
            "Epoch 9/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 11.4615<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 5.8392 <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 6/16 [==========>...................] - ETA: 0s - loss: 4.4943<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 9/16 [===============>..............] - ETA: 0s - loss: 3.9304<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "11/16 [===================>..........] - ETA: 0s - loss: 3.4037<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "14/16 [=========================>....] - ETA: 0s - loss: 3.0586<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 4.1784 - val_loss: 13.6336\n",
            "Epoch 10/10\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 5.5530<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 4/16 [======>.......................] - ETA: 0s - loss: 6.2119<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            " 7/16 [============>.................] - ETA: 0s - loss: 4.6644<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "10/16 [=================>............] - ETA: 0s - loss: 4.1273<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "13/16 [=======================>......] - ETA: 0s - loss: 4.2155<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - ETA: 0s - loss: 6.2456<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 6.2456 - val_loss: 12.1459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05b02f0c10>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "SHOYAvffxwwl",
        "outputId": "2e307b7c-7ade-4d76-e02b-8eb469ecba52"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_8bE3iA_q8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}