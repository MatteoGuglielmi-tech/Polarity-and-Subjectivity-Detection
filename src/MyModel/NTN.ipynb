{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/src/MyModel/NTN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NTN (Neural Tensor Network) [[reference_paper](https://proceedings.neurips.cc/paper/2013/file/b337e84de8752b27eda3a12363109e80-Paper.pdf)]\n",
        "\n",
        "<u><i>Goal</i></u> : state if two entities $(e_1, e_2)$ are in a certain relationship $R$.   \n",
        ">Ex. defines whehter $$(e_1, R, e_2) = (\\text{Bengal tiger}, \\text{has part}, \\text{tail})$$ is true and with which certainty.\n",
        "\n",
        "- $e_1$ and $e_2$ are vector representations or features of the two entities.\n",
        "- NTN, unlike a linear canoncical NN layer, uses a bilinear tensor layer that directly relates two entity vectors across differet dimensions.\n",
        "- Model computes a score of how likely it is two entities are in a specific position following : $$g(e_1, R, e_2) = u_R^Tf\\biggr(e_i^T W_R^{[1:K]}e_2+V_R \\begin{align}\n",
        "    \\begin{bmatrix}\n",
        "           e_{1} \\\\\n",
        "           e_{2} \\\\\n",
        "         \\end{bmatrix}\n",
        "  \\end{align} + b_R\\Biggl)$$  \n",
        "where : \n",
        "- $f=\\tanh$\n",
        "- $W_R^{[1:K]} \\in \\mathbb{R}^{d\\times d\\times k}$ is a multi-dimensional tensor\n",
        "- $e_1^TW_R^{[1:k]}e_2=h\\in\\mathbb{R}$ is the bilinear tensor\n",
        "- $V_R \\in \\mathbb{R}^{k\\times2d}$, $U \\in \\mathbb{R}^K$, $b_R\\in \\mathbb{R}^K$ are NN parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KuB3DKrgQfSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### pytorch trials"
      ],
      "metadata": {
        "id": "Tq-h_R_lEKwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4WlxO-pC-Pmo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Tuple, List\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralTensorNetwork(nn.Module):\n",
        "    def __init__(self, output_dim: int, input_dim: int, activation: str=\"tanh\", mean: float=0.0, std: float=1.0):\n",
        "        \n",
        "        super(NeuralTensorNetwork, self).__init__()\n",
        "\n",
        "        # setting input and output dimensions\n",
        "        self.k = output_dim\n",
        "        self.d = input_dim # e1,e2\n",
        "\n",
        "        # setting mean and std for random initialization\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "        # parameters has been used in order to consider W, V, b as model parameters\n",
        "        # inference -> they'll be optimized\n",
        "\n",
        "        # normal sampling -> https://pytorch.org/docs/stable/generated/torch.normal.html\n",
        "        # parameter -> https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter\n",
        "        self.W = nn.Parameter(torch.normal(self.mean, self.std, size=(self.k, self.d, self.d)))\n",
        "        self.V = nn.Parameter(torch.normal(self.mean, self.std, size=(2*self.d, self.k)))\n",
        "        self.b = nn.Parameter(torch.zeros(size=(self.d,)))\n",
        "        \n",
        "        print(f\"self.W : {torch.Tensor.size(self.W)}\")\n",
        "        print(f\"self.V : {torch.Tensor.size(self.V)}\")\n",
        "        print(f\"self.b : {torch.Tensor.size(self.b)}\")\n",
        "        \n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif self.activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        # checking for a good activation function\n",
        "        else:\n",
        "            raise ValueError('Possible activation choices are tanh, sigmoid or ReLU')\n",
        "\n",
        "    def forward(self, inputs: List[torch.Tensor]) -> torch.Tensor:\n",
        "\n",
        "        # getting the entities\n",
        "        e1 = inputs[0]\n",
        "        e2 = inputs[1]\n",
        "        print(f\"e1.shape : {torch.Tensor.size(e1)}\")\n",
        "        print(f\"e2.shape : {torch.Tensor.size(e2)}\")\n",
        "        print(f\"self.W[0] : {torch.Tensor.size(self.W[0])}\")\n",
        "        print(f\"self.V : {torch.Tensor.size(self.V)}\")\n",
        "        print(f\"self.bias : {torch.Tensor.size(self.b)}\")\n",
        "        print(f\"batch_size : {torch.clone(e1).cpu().numpy().shape[0]}\")\n",
        "        print(f\"k : {self.k}\")\n",
        "        print(f\"torch.cat([e1,e2], dim=1) : {torch.Tensor.size(torch.cat([e1,e2], dim=1))}\")\n",
        "        \n",
        "\n",
        "        # input tensor should be of shape (batch_size, padded_length, 768)\n",
        "        batch_size = torch.clone(e1).cpu().numpy().shape[0]\n",
        "        k = self.k\n",
        "        d = self.d\n",
        "\n",
        "        # print(f\"dot prod : {torch.matmul(e1, self.W[0])}\")\n",
        "        print(f\"dot prod size: {torch.Tensor.size(torch.matmul(e1, self.W[0]))}\")\n",
        "\n",
        "        # bilinear tensor + bias\n",
        "        bil_bias = [torch.sum((e2 * torch.matmul(e1, self.W[0])) + self.b, axis=1)]\n",
        "        \n",
        "        for i in range(1,k):\n",
        "            bil_bias.append(torch.sum((e2*torch.matmul(e1, self.W[i])) + self.b, axis=1))\n",
        "        \n",
        "        bil_bias = torch.cat(bil_bias, axis=0)\n",
        "        bil_bias = torch.reshape(bil_bias, (batch_size, k))\n",
        "\n",
        "        # Vr * [e1, e2]\n",
        "        rest = torch.matmul(torch.cat([e1,e2], dim=1), self.V)\n",
        "\n",
        "        e1_R_e2 = bil_bias + rest\n",
        "\n",
        "        # applying activation\n",
        "        f = self.activation(e1_R_e2)\n",
        "        return f"
      ],
      "metadata": {
        "id": "-anTmLwuTLvR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batching_data(dataset, batch_size: int=64) -> torch.utils.data.DataLoader:\n",
        "    dataloader = DataLoader(dataset=dataset, sampler=RandomSampler(dataset), batch_size=batch_size, shuffle=False)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "FtBwT8k8z-89"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll = []\n",
        "i = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "ll.append(i)\n",
        "for k in range(0,10):\n",
        "    ll.append(np.zeros(i.shape))\n",
        "\n",
        "print(ll)\n",
        "\n",
        "\n",
        "l = []\n",
        "\n",
        "j = np.array([11,12,13,14,15,16,17,18,19,20])\n",
        "l.append(j)\n",
        "for z in range(0,10):\n",
        "    l.append(np.ones(j.shape))\n",
        "\n",
        "print(l)\n",
        "\n",
        "print(np.array(l).shape)\n",
        "print(np.array(ll).shape)\n",
        "\n",
        "y = np.random.random((len(l),1))\n",
        "y.shape"
      ],
      "metadata": {
        "outputId": "b7e891b7-bc48-45ab-bdb2-8eae478a1e16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qxlLJz7YbBm"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
            "[array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])]\n",
            "(11, 10)\n",
            "(11, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e1_dataloader = batching_data(np.array(ll), batch_size=4)\n",
        "e2_dataloader = batching_data(np.array(l), batch_size=4)"
      ],
      "metadata": {
        "id": "jVIm2yo9gzLB"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e1_dataloader"
      ],
      "metadata": {
        "id": "BABMrSGzhU_t",
        "outputId": "7e7d8c04-547d-4d9b-eba9-92d8bbc59e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe729437dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e2_dataloader"
      ],
      "metadata": {
        "id": "oc9Gy7bdjfKe",
        "outputId": "847637b9-de84-47af-87c2-729c9cb07a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe729437210>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, i in enumerate(iter(e2_dataloader)):\n",
        "    for element in i :\n",
        "        print(idx, element)"
      ],
      "metadata": {
        "id": "TL4SNMYbOjJd",
        "outputId": "47454b91-3c8b-4dc3-81de-a14c44329505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "0 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "0 tensor([11., 12., 13., 14., 15., 16., 17., 18., 19., 20.], dtype=torch.float64)\n",
            "0 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "1 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "1 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "1 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "1 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "2 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "2 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "2 tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(iter(e1_dataloader))\n",
        "\n",
        "for i in range (len(iter(e1_dataloader))):\n",
        "  print(next(iter(e1_dataloader)))"
      ],
      "metadata": {
        "id": "_6N1FEmri_4R",
        "outputId": "fd24ea05-f6ed-46ed-b4a3-14d146fe84cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(iter(e2_dataloader))\n",
        "\n",
        "for i in range (len(iter(e2_dataloader))):\n",
        "  print(next(iter(e2_dataloader)))"
      ],
      "metadata": {
        "id": "cNI4NePvhf1t",
        "outputId": "8aaad88e-483d-4e5c-952f-e0f8b11fcbe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mse() -> torch.nn.MSELoss:\n",
        "    return nn.MSELoss()"
      ],
      "metadata": {
        "id": "MoLLwKrUpo2E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(model, lr):\n",
        "    return torch.optim.Adam(model.parameters(), lr)"
      ],
      "metadata": {
        "id": "Kygj0APpqNMy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, e1_dataloader, e2_dataloader, target_dataloader=None, device='cuda'):\n",
        "    # converting the two dataloaders in iterators\n",
        "    print('training')\n",
        "    e1_iterator = iter(e1_dataloader)\n",
        "    e2_iterator = iter(e2_dataloader)\n",
        "\n",
        "    # vector of target values (gt)\n",
        "    if target_dataloader!= None:\n",
        "        target_iter = iter(target_dataloader)\n",
        "\n",
        "    # getting lengths \n",
        "    iter1_length = len(e1_iterator)\n",
        "    iter2_length = len(e2_iterator)\n",
        "\n",
        "    flag = 0\n",
        "    #loss = get_mse()\n",
        "    optimizer = get_optimizer(model, 0.001)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if iter1_length > iter2_length:\n",
        "        flag = 1\n",
        "    elif iter2_length > iter1_length:\n",
        "        flag = 2\n",
        "\n",
        "    if flag==1:\n",
        "        for i in range(iter2_length):\n",
        "        # if the second entity's vector is longer than the first one\n",
        "        # I need to deal with this case\n",
        "        # With the devised solution, once the first iterator has reached the end \n",
        "        # it will be reinitialized \n",
        "            try:\n",
        "                e1_input = next(e1_iterator)\n",
        "                e1_input = e1_input.to(device)\n",
        "                if target_dataloader!=None:\n",
        "                    target = next(target_iter)\n",
        "                    target = target.to(device)\n",
        "            except:\n",
        "                e1_iterator = iter(e1_dataloader)\n",
        "                e1_input = next(e1_iterator)\n",
        "                e1_input = e1_input.to(device)\n",
        "                if target_dataloader!=None:\n",
        "                    target_iter = iter(target_dataloader)\n",
        "                    target = next(target_iter)\n",
        "                    target = target.to(device)\n",
        "\n",
        "            # at this point, al inputs are loaded on GPU\n",
        "            outputs = model([e1_input, e2_input]) # call method\n",
        "            if target_dataloader==None:\n",
        "                continue\n",
        "            loss = get_mse(outputs, target)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            print(f'outputs: {outputs}')\n",
        "\n",
        "    elif flag==2:\n",
        "        for i in range(iter1_length):\n",
        "            try:\n",
        "                e2_input = next(e2_iterator)\n",
        "                e2_input = e2_input.to(device)\n",
        "                target = next(target_iter)\n",
        "                target = target.to(device)\n",
        "            except:\n",
        "                e2_iterator = iter(e2_dataloader)\n",
        "                e2_input = next(e2_iterator)\n",
        "                e2_input = e2_input.to(device)\n",
        "                target_iter = iter(target_dataloader)\n",
        "                target = next(target_iter)\n",
        "                target = target.to(device)\n",
        "\n",
        "            outputs = model([e1_input, e2_input]) # call method\n",
        "            if target_dataloader==None:\n",
        "                continue\n",
        "            loss = get_mse(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "    \n",
        "    elif flag==0:\n",
        "        for e1, e2 in zip(e1_iterator, e2_iterator):\n",
        "            #for element1, element2 in zip(e1,e2):\n",
        "                # in case they have the same length\n",
        "                #for i in range(iter1_length):\n",
        "            #    e1_input = element1.to(device)\n",
        "            #    e2_input = element2.to(device)\n",
        "                #print(e1_input)\n",
        "                #print(e2_input)\n",
        "            #    outputs = model([e1_input, e2_input]) # forward method\n",
        "        \n",
        "            #    loss.backward()\n",
        "            #    optimizer.step()\n",
        "            #    optimizer.zero_grad()\n",
        "            if target_dataloader!=None:\n",
        "                target = next(target_iter)\n",
        "                target = target.to(device)\n",
        "\n",
        "            # in this way I'm extracting the batches\n",
        "            print(f\"e1 : {e1.shape}\")\n",
        "            print(f\"e2 : {e2.shape}\")\n",
        "\n",
        "            e1_input = e1.to(device)\n",
        "            e2_input = e2.to(device)\n",
        "            outputs = model([e1_input, e2_input]) # forward method\n",
        "            if target_dataloader==None:\n",
        "                continue\n",
        "            loss = get_mse(outputs, target)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "3yhW3NFHjsnr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dataloaders, epochs=5, device='cuda'):\n",
        "    model = NeuralTensorNetwork(output_dim=32, input_dim=10)\n",
        "    model = model.double().to(device)\n",
        "    for e in range(epochs):\n",
        "    # def training_step(model, e1_dataloader, e2_dataloader, device='cuda'):\n",
        "        training_step(model, dataloaders[0], dataloaders[1]) \n",
        "        print(e)\n",
        "    print('Traning done')"
      ],
      "metadata": {
        "id": "8_HKAPHSHOsx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main([e1_dataloader, e2_dataloader])"
      ],
      "metadata": {
        "id": "MUzSiL92JgIP",
        "outputId": "577b3932-4a8d-4fea-d6ff-6fc4bda8af31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.W : torch.Size([32, 10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.b : torch.Size([10])\n",
            "training\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([3, 10])\n",
            "e2 : torch.Size([3, 10])\n",
            "e1.shape : torch.Size([3, 10])\n",
            "e2.shape : torch.Size([3, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 3\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([3, 20])\n",
            "dot prod size: torch.Size([3, 10])\n",
            "0\n",
            "training\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([3, 10])\n",
            "e2 : torch.Size([3, 10])\n",
            "e1.shape : torch.Size([3, 10])\n",
            "e2.shape : torch.Size([3, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 3\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([3, 20])\n",
            "dot prod size: torch.Size([3, 10])\n",
            "1\n",
            "training\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([3, 10])\n",
            "e2 : torch.Size([3, 10])\n",
            "e1.shape : torch.Size([3, 10])\n",
            "e2.shape : torch.Size([3, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 3\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([3, 20])\n",
            "dot prod size: torch.Size([3, 10])\n",
            "2\n",
            "training\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([3, 10])\n",
            "e2 : torch.Size([3, 10])\n",
            "e1.shape : torch.Size([3, 10])\n",
            "e2.shape : torch.Size([3, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 3\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([3, 20])\n",
            "dot prod size: torch.Size([3, 10])\n",
            "3\n",
            "training\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([4, 10])\n",
            "e2 : torch.Size([4, 10])\n",
            "e1.shape : torch.Size([4, 10])\n",
            "e2.shape : torch.Size([4, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 4\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([4, 20])\n",
            "dot prod size: torch.Size([4, 10])\n",
            "e1 : torch.Size([3, 10])\n",
            "e2 : torch.Size([3, 10])\n",
            "e1.shape : torch.Size([3, 10])\n",
            "e2.shape : torch.Size([3, 10])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 3\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([3, 20])\n",
            "dot prod size: torch.Size([3, 10])\n",
            "4\n",
            "Traning done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### to collapse"
      ],
      "metadata": {
        "id": "bfw_Ard1YVR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Dummy training data\n",
        "x_train1 = np.random.random((1000, 300))\n",
        "x_train2 = np.random.random((1000, 300))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Dummy validation data\n",
        "x_val1 = np.random.random((100, 300))\n",
        "x_val2 = np.random.random((100, 300))\n",
        "y_val = np.random.random((100, 1))\n",
        "\n",
        "\n",
        "print ('Shape of Training Data: ', x_train1.shape, x_train2.shape, y_train.shape)\n",
        "print ('Shape of Validation Data', x_val1.shape, x_val2.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "TXq4IXC-pYRW",
        "outputId": "34c98224-61cf-489e-ca7e-68b999e04050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:  (1000, 300) (1000, 300) (1000, 1)\n",
            "Shape of Validation Data (100, 300) (100, 300) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2 = batching_data([x_train1, x_train2])"
      ],
      "metadata": {
        "id": "7xvVymYO2uAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x1)"
      ],
      "metadata": {
        "id": "XlE35uqf7ItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x2)"
      ],
      "metadata": {
        "id": "7FgpHwh97N1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensrflow Version"
      ],
      "metadata": {
        "id": "XYzKkf7VEREB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K  # in keras simple computations are not handled directly but it relies on a well optimized tensor handler library\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "2zWIRcpstrr1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralTensorLayer(Layer):\n",
        "    def __init__(self, output_dim, input_dim, activation= None):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim #The k in the formula\n",
        "        self.input_dim = input_dim   #The d in the formula\n",
        "        self.activation = activation #The f function in the formula\n",
        "        \n",
        "    # called the first time call is called\n",
        "    def build(self, input_shape):\n",
        "        #The initialisation parameters\n",
        "        self.mean = 0.0 \n",
        "        self.stddev = 1.0\n",
        "        dtype = 'float32'\n",
        "        self.seed = 1\n",
        "        \n",
        "        #The output and the inut dimension\n",
        "        k = self.output_dim\n",
        "        d = self.input_dim\n",
        "        \n",
        "        #Initialise the variables to be trained. The variables are according to the\n",
        "        #function defined.\n",
        "        self.W = K.variable(K.random_normal((k,d,d), self.mean, self.stddev,\n",
        "                               dtype=dtype, seed=self.seed))\n",
        "        self.V = K.variable(K.random_normal((2*d,k), self.mean, self.stddev,\n",
        "                               dtype=dtype, seed=self.seed))\n",
        "        self.b = K.zeros((self.input_dim,))\n",
        "        \n",
        "        #Set the variables to be trained.\n",
        "        self._trainable_weights = [self.W, self.V, self.b]\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        #Get Both the inputs\n",
        "        e1 = inputs[0]\n",
        "        e2 = inputs[1]\n",
        "\n",
        "        #tf.print(\"\\n\")\n",
        "        #tf.print(\"e1.shape : \", tf.shape(e1))\n",
        "        #tf.print(\"e2.shape : \", tf.shape(e2))\n",
        "        #tf.print(\"W[0].shape : \", tf.shape(self.W[0]))\n",
        "        #tf.print(\"V.shape : \", tf.shape(self.V))\n",
        "        #tf.print(\"b.shape : \", tf.shape(self.b))\n",
        "        #tf.print(\"batch_size : \", K.shape(e1)[0])\n",
        "\n",
        "        #Get the batch size\n",
        "        batch_size = K.shape(e1)[0]\n",
        "        \n",
        "        #The output and the inut dimension\n",
        "        k = self.output_dim\n",
        "        d = self.input_dim\n",
        "\n",
        "        #The first term in the function which is the bilinear product is calculated here.\n",
        "        first_term_k = [K.sum((e2 * K.dot(e1, self.W[0])) + self.b, axis=1)]\n",
        "        #tf.print(\"K.dot : \" , K.dot(e1,self.W[0]))\n",
        "        #tf.print(\"K.dot shape : \" , tf.shape(K.dot(e1,self.W[0])))\n",
        "        for i in range(1, k):\n",
        "            temp = K.sum((e2 * K.dot(e1, self.W[i])) + self.b, axis=1)\n",
        "            first_term_k.append(temp)\n",
        "        first_term = K.concatenate(first_term_k, axis=0) \n",
        "        #tf.print(\"first_term size :\", tf.shape(first_term))\n",
        "        \n",
        "        first_term = K.reshape(first_term, (batch_size, k))\n",
        "\n",
        "        #tf.print(\"first_term size :\", tf.shape(first_term))\n",
        "\n",
        "        #The second term in the function is calculated here.\n",
        "        second_term = K.dot(K.concatenate([e1,e2]), self.V)\n",
        "        \n",
        "        #Sum of the two terms to get the final function\n",
        "        z =  first_term + second_term\n",
        " \n",
        "        # The activation is selected here\n",
        "        if (self.activation == None):\n",
        "            return z\n",
        "        elif (self.activation == 'tanh'):\n",
        "            return K.tanh(z)\n",
        "        elif (self.activation == 'relu'):\n",
        "            #tf.print(K.relu(z))\n",
        "            return K.relu(z)\n",
        "        else :\n",
        "            print ('Activation not found')\n",
        "        "
      ],
      "metadata": {
        "id": "7c9WtJoGtl1b"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here Define the model\n",
        "vector1 = Input(shape=(10,), dtype='float32')\n",
        "vector2 = Input(shape=(10,), dtype='float32')\n",
        "BilinearLayer = NeuralTensorLayer(output_dim=32, input_dim=10, \n",
        "                                  activation= 'relu')([vector1, vector2])\n",
        "\n",
        "g = Dense(1)(BilinearLayer)\n",
        "\n",
        "#The g or the output of the modelled function.\n",
        "model = Model(inputs=[vector1, vector2], outputs=[g])\n",
        "\n",
        "#Compile the model\n",
        "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "#The summary of the model.\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssnK68owuovX",
        "outputId": "56aec532-54cc-40aa-e67c-4d1067bcea6d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " neural_tensor_layer_1 (NeuralT  (None, 32)          3850        ['input_3[0][0]',                \n",
            " ensorLayer)                                                      'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            33          ['neural_tensor_layer_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,883\n",
            "Trainable params: 3,883\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "SHOYAvffxwwl",
        "outputId": "2776f040-f15e-4823-e531-3b77867f581a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll = []\n",
        "i = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "ll.append(i)\n",
        "for k in range(0,10):\n",
        "    ll.append(np.zeros(i.shape))\n",
        "\n",
        "print(ll)\n",
        "\n",
        "\n",
        "l = []\n",
        "\n",
        "j = np.array([11,12,13,14,15,16,17,18,19,20])\n",
        "l.append(j)\n",
        "for z in range(0,10):\n",
        "    l.append(np.ones(j.shape))\n",
        "\n",
        "print(l)\n",
        "\n",
        "print(np.array(l).shape)\n",
        "print(np.array(ll).shape)\n",
        "\n",
        "y = np.random.random((len(l),1))\n",
        "y.shape"
      ],
      "metadata": {
        "id": "k_8bE3iA_q8U",
        "outputId": "70577939-2d2c-409c-bfed-6f90377528a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
            "[array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])]\n",
            "(11, 10)\n",
            "(11, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(([np.array(ll), np.array(l)]), y, batch_size=4, epochs=10)"
      ],
      "metadata": {
        "id": "gpLKGofgrq29",
        "outputId": "6b0678af-f424-4dc3-ee19-b372198db5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 3s 12ms/step - loss: 79629.3672\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 177705.6094\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 30667.2109\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 165620.4375\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 88233.2422\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 156021.5938\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 148106.1719\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 141851.0312\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 32416.1699\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 29716.0879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe72c748310>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Dummy training data\n",
        "x_train1 = np.random.random((1000, 300))\n",
        "x_train2 = np.random.random((1000, 300))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Dummy validation data\n",
        "x_val1 = np.random.random((100, 300))\n",
        "x_val2 = np.random.random((100, 300))\n",
        "y_val = np.random.random((100, 1))\n",
        "\n",
        "print ('Shape of Training Data: ', x_train1.shape, x_train2.shape, y_train.shape)\n",
        "print ('Shape of Validation Data', x_val1.shape, x_val2.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxiWrtEXuoJ7",
        "outputId": "3ba7e21e-de91-40d5-ff22-90223752b15d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:  (1000, 300) (1000, 300) (1000, 1)\n",
            "Shape of Validation Data (100, 300) (100, 300) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here Define the model\n",
        "vector1 = Input(shape=(300,), dtype='float32')\n",
        "vector2 = Input(shape=(300,), dtype='float32')\n",
        "BilinearLayer = NeuralTensorLayer(output_dim=32, input_dim=300, \n",
        "                                  activation= 'relu')([vector1, vector2])\n",
        "\n",
        "g = Dense(1)(BilinearLayer)\n",
        "\n",
        "#The g or the output of the modelled function.\n",
        "model = Model(inputs=[vector1, vector2], outputs=[g])\n",
        "\n",
        "#Compile the model\n",
        "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "#The summary of the model.\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b94403b-c14f-4b96-af30-b89a8abac09b",
        "id": "6r8LSnNwTlm4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " neural_tensor_layer_2 (NeuralT  (None, 32)          2899500     ['input_5[0][0]',                \n",
            " ensorLayer)                                                      'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            33          ['neural_tensor_layer_2[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,899,533\n",
            "Trainable params: 2,899,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([x_train1, x_train2], y_train,\n",
        "          batch_size=64, epochs=10,\n",
        "          validation_data=([x_val1, x_val2], y_val))"
      ],
      "metadata": {
        "id": "8uGv2VC0uz_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6ee49a-c308-4c92-8c8f-cb3d9a2af11a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 3s 41ms/step - loss: 3176.0068 - val_loss: 10.5460\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 5.9429 - val_loss: 1.0483\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.3358 - val_loss: 0.5798\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.8591 - val_loss: 0.5033\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.8173 - val_loss: 0.4845\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.2097 - val_loss: 0.4702\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.7599 - val_loss: 0.4568\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 1.2153 - val_loss: 0.4334\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.7543 - val_loss: 0.4197\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.5281 - val_loss: 0.4113\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7c0445610>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e1_dataloader = batching_data(x_train1, batch_size=64)\n",
        "e2_dataloader = batching_data(x_train2, batch_size=64)\n",
        "y_dataloader = batching_data(y_train, batch_size=64)\n",
        "\n",
        "main([e1_dataloader, e2_dataloader, y_dataloader], epochs=10)\n"
      ],
      "metadata": {
        "id": "MAfk6lLpbjOi",
        "outputId": "d6b3d4d7-f91d-41f6-9ab2-8c52eae4222a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.W : torch.Size([32, 10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.b : torch.Size([10])\n",
            "training\n",
            "e1 : torch.Size([64, 300])\n",
            "e2 : torch.Size([64, 300])\n",
            "e1.shape : torch.Size([64, 300])\n",
            "e2.shape : torch.Size([64, 300])\n",
            "self.W[0] : torch.Size([10, 10])\n",
            "self.V : torch.Size([20, 32])\n",
            "self.bias : torch.Size([10])\n",
            "batch_size : 64\n",
            "k : 32\n",
            "torch.cat([e1,e2], dim=1) : torch.Size([64, 600])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1ec254921be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatching_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me1_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dataloader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-889ec32f9d4b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataloaders, epochs, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# def training_step(model, e1_dataloader, e2_dataloader, device='cuda'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Traning done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-baeea62897d4>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, e1_dataloader, e2_dataloader, target_dataloader, device)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0me1_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0me2_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me1_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-21fb0eee4ef7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# print(f\"dot prod : {torch.matmul(e1, self.W[0])}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dot prod size: {torch.Tensor.size(torch.matmul(e1, self.W[0]))}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# bilinear tensor + bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x300 and 10x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkBVwajri-bH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}