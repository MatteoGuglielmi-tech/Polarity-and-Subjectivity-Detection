{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzj4mJhRrUNbpU9WDqayRH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/src/MyModel/NTN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NTN (Neural Tensor Network) [[reference_paper](https://proceedings.neurips.cc/paper/2013/file/b337e84de8752b27eda3a12363109e80-Paper.pdf)]\n",
        "\n",
        "<u><i>Goal</i></u> : state if two entities $(e_1, e_2)$ are in a certain relationship $R$.   \n",
        ">Ex. defines whehter $$(e_1, R, e_2) = (\\text{Bengal tiger}, \\text{has part}, \\text{tail})$$ is true and with which certainty.\n",
        "\n",
        "- $e_1$ and $e_2$ are vector representations or features of the two entities.\n",
        "- NTN, unlike a linear canoncical NN layer, uses a bilinear tensor layer that directly relates two entity vectors across differet dimensions.\n",
        "- Model computes a score of how likely it is two entities are in a specific position following : $$g(e_1, R, e_2) = u_R^Tf\\biggr(e_i^T W_R^{[1:K]}e_2+V_R \\begin{align}\n",
        "    \\begin{bmatrix}\n",
        "           e_{1} \\\\\n",
        "           e_{2} \\\\\n",
        "         \\end{bmatrix}\n",
        "  \\end{align} + b_R\\Biggl)$$  \n",
        "where : \n",
        "- $f=\\tanh$\n",
        "- $W_R^{[1:K]} \\in \\mathbb{R}^{d\\times d\\times k}$ is a multi-dimensional tensor\n",
        "- $e_1^TW_R^{[1:k]}e_2=h\\in\\mathbb{R}$ is the bilinear tensor\n",
        "- $V_R \\in \\mathbb{R}^{k\\times2d}$, $U \\in \\mathbb{R}^K$, $b_R\\in \\mathbb{R}^K$ are NN parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KuB3DKrgQfSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### pytorch trials"
      ],
      "metadata": {
        "id": "Tq-h_R_lEKwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4WlxO-pC-Pmo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralTensorNetwork(nn.Module):\n",
        "    def __init__(self, output_dim: int, input_dim: int, activation: str=\"tanh\", mean: float=0.0, std: float=1.0):\n",
        "        \n",
        "        super(NeuralTensorNetwork, self).__init__()\n",
        "\n",
        "        # setting input and output dimensions\n",
        "        self.k = output_dim\n",
        "        self.d = input_dim # e1,e2\n",
        "\n",
        "        # setting mean and std for random initialization\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "        # parameters has been used in order to consider W, V, b as model parameters\n",
        "        # inference -> they'll be optimized\n",
        "\n",
        "        # normal sampling -> https://pytorch.org/docs/stable/generated/torch.normal.html\n",
        "        # parameter -> https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter\n",
        "        self.W = nn.Parameter(torch.normal(self.mean, self.std, size=(self.k, self.d, self.d)))\n",
        "        self.V = nn.Parameter(torch.normal(self.mean, self.std, size=(2*self.d, self.k)))\n",
        "        self.b = nn.Parameter(torch.zeros(size=(self.d,)))\n",
        "        \n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif self.activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        # checking for a good activation function\n",
        "        else:\n",
        "            raise ValueError('Possible activation choices are tanh, sigmoid or ReLU')\n",
        "\n",
        "    def forward(self, inputs: Tuple[torch.Tensor, torch.Tensor]):\n",
        "\n",
        "        # getting the entities\n",
        "        e1 = inputs[0]\n",
        "        e2 = inputs[1]\n",
        "\n",
        "        # input tensor should be of shape (batch_size, padded_length, 768)\n",
        "        batch_size = e1[0]\n",
        "        k = self.k\n",
        "        d = self.d\n",
        "\n",
        "        # bilinear tensor + bias\n",
        "        bil_bias = [torch.sum((e2 * torch.dot(e1, self.W[0])) + self.b, axis=1)]\n",
        "        for i in range(1,k):\n",
        "            bil_bias.append(torch.sum((e2*torch.dot(e1, self.W[i]))) + self.b, axis=1)\n",
        "        bil_bias = torch.reshape(torch.cat(bil_bias, axis=0), (batch_size, k))\n",
        "\n",
        "        # Vr * [e1, e2]\n",
        "        rest = torch.dot(torch.cat([e1,e2]), self.V)\n",
        "\n",
        "        e1_R_e2 = bil_bias + rest\n",
        "\n",
        "        # applying activation\n",
        "        f = self.activation(e1_R_e2)\n",
        "        return f"
      ],
      "metadata": {
        "id": "-anTmLwuTLvR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batching_data(data: Tuple[np.array, np.array], batch_size: int=64) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
        "    x1 = DataLoader(dataset=data[0], sampler=RandomSampler(data[0]), batch_size=64, shuffle=False)\n",
        "    x2 = DataLoader(dataset=data[1], sampler=RandomSampler(data[1]), batch_size=64, shuffle=False)\n",
        "    return x1, x2 "
      ],
      "metadata": {
        "id": "FtBwT8k8z-89"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Dummy training data\n",
        "x_train1 = np.random.random((1000, 300))\n",
        "x_train2 = np.random.random((1000, 300))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Dummy validation data\n",
        "x_val1 = np.random.random((100, 300))\n",
        "x_val2 = np.random.random((100, 300))\n",
        "y_val = np.random.random((100, 1))\n",
        "\n",
        "\n",
        "print ('Shape of Training Data: ', x_train1.shape, x_train2.shape, y_train.shape)\n",
        "print ('Shape of Validation Data', x_val1.shape, x_val2.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "TXq4IXC-pYRW",
        "outputId": "b48f26e3-dd34-4699-f41d-4fd412c70c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:  (1000, 300) (1000, 300) (1000, 1)\n",
            "Shape of Validation Data (100, 300) (100, 300) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2 = batching_data([x_train1, x_train2])"
      ],
      "metadata": {
        "id": "7xvVymYO2uAk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlE35uqf7ItV",
        "outputId": "d207aaa8-0855-460b-a696-d518aa71506a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FgpHwh97N1N",
        "outputId": "a3c33fdc-9f83-4248-9e3e-aa8725c1992b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mse() -> torch.nn.MSELoss:\n",
        "    return nn.MSELoss()"
      ],
      "metadata": {
        "id": "MoLLwKrUpo2E"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(model, lr):\n",
        "    return torch.optim.Adam(model.parameters(), lr)"
      ],
      "metadata": {
        "id": "Kygj0APpqNMy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    bilinear : NeuralTensorNetwork(output_dim=32, input_dim=300, activation='relu')\n",
        "    g : nn.Linear(in_features=32, out_features=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        bilinear = bilinear(x)\n",
        "        dense = g(bilinear)\n",
        "\n",
        "        return dense\n"
      ],
      "metadata": {
        "id": "oXYJHYFm_Fqr"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, data, optimizer, cf, targets, device='cuda'):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "    cumulative_accuracy = 0.\n",
        "  \n",
        "    model.train() \n",
        " \n",
        "    # iterate over the training set\n",
        "    for batch_idx, inputs in enumerate(data):\n",
        "        # load data into GPU\n",
        "        input1 = inputs[0].to(device)\n",
        "        input2 = inputs[1].to(device)\n",
        "        inputs = [input1, input2]\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # loss computation\n",
        "        loss = get_mse(outputs, targets)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "    \n",
        "        # parameters update\n",
        "        optimizer.step()\n",
        "\n",
        "        # gradients reset\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # fetch prediction and loss value\n",
        "        samples += inputs.shape[0]\n",
        "        cumulative_loss += loss.item()\n",
        "        _, predicted = outputs.max(dim=1) # max() returns (maximum_value, index_of_maximum_value)\n",
        "\n",
        "        # compute training accuracy\n",
        "        cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "UWog0GYEq7fD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    model = NeuralTensorNetwork(output_dim=32, input_dim=300, activation='relu').to('cuda')\n",
        "    optimizer = get_optimizer(model, 0.001)\n",
        "    loss = get_mse()\n",
        "\n",
        "    data = batching_data([x_train1, x_train2])\n",
        "\n",
        "    for e in range(0,5):\n",
        "        train_loss, train_accuracy = training_step(model, data, optimizer, loss, y_train, 'cuda')\n",
        "        print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n"
      ],
      "metadata": {
        "id": "hPV92aDducGF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "3yg72_9i1BSk",
        "outputId": "104d7a3a-b72d-4852-d68a-584ee00b6d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-489d983485c9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-66743d9c4e04>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, data, optimizer, cf, targets, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# load data into GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensrflow Version"
      ],
      "metadata": {
        "id": "XYzKkf7VEREB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "2zWIRcpstrr1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralTensorLayer(Layer):\n",
        "    def __init__(self, output_dim, input_dim, activation= None):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim #The k in the formula\n",
        "        self.input_dim = input_dim   #The d in the formula\n",
        "        self.activation = activation #The f function in the formula\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        #The initialisation parameters\n",
        "        self.mean = 0.0 \n",
        "        self.stddev = 1.0\n",
        "        dtype = 'float32'\n",
        "        self.seed = 1\n",
        "        \n",
        "        #The output and the inut dimension\n",
        "        k = self.output_dim\n",
        "        d = self.input_dim\n",
        "        \n",
        "        #Initialise the variables to be trained. The variables are according to the\n",
        "        #function defined.\n",
        "        self.W = K.variable(K.random_normal((k,d,d), self.mean, self.stddev,\n",
        "                               dtype=dtype, seed=self.seed))\n",
        "        self.V = K.variable(K.random_normal((2*d,k), self.mean, self.stddev,\n",
        "                               dtype=dtype, seed=self.seed))\n",
        "        self.b = K.zeros((self.input_dim,))\n",
        "        \n",
        "        #Set the variables to be trained.\n",
        "        self._trainable_weights = [self.W, self.V, self.b]\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        #Get Both the inputs\n",
        "        e1 = inputs[0]\n",
        "        e2 = inputs[1]\n",
        "        \n",
        "        #Get the batch size\n",
        "        batch_size = K.shape(e1)[0]\n",
        "        \n",
        "        #The output and the inut dimension\n",
        "        k = self.output_dim\n",
        "        d = self.input_dim\n",
        "\n",
        "        #The first term in the function which is the bilinear product is calculated here.\n",
        "        first_term_k = [K.sum((e2 * K.dot(e1, self.W[0])) + self.b, axis=1)]\n",
        "        for i in range(1, k):\n",
        "            temp = K.sum((e2 * K.dot(e1, self.W[i])) + self.b, axis=1)\n",
        "            first_term_k.append(temp)\n",
        "        first_term = K.reshape(K.concatenate(first_term_k, axis=0), (batch_size, k))\n",
        "\n",
        "        #The second term in the function is calculated here.\n",
        "        second_term = K.dot(K.concatenate([e1,e2]), self.V)\n",
        "        \n",
        "        #Sum of the two terms to get the final function\n",
        "        z =  first_term + second_term\n",
        "        \n",
        "        #The activation is selected here\n",
        "        if (self.activation == None):\n",
        "            return z\n",
        "        elif (self.activation == 'tanh'):\n",
        "            return K.tanh(z)\n",
        "        elif (self.activation == 'relu'):\n",
        "            return K.relu(z)\n",
        "        else :\n",
        "            print ('Activation not found')\n"
      ],
      "metadata": {
        "id": "7c9WtJoGtl1b"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Dummy training data\n",
        "x_train1 = np.random.random((1000, 300))\n",
        "x_train2 = np.random.random((1000, 300))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Dummy validation data\n",
        "x_val1 = np.random.random((100, 300))\n",
        "x_val2 = np.random.random((100, 300))\n",
        "y_val = np.random.random((100, 1))\n",
        "\n",
        "print ('Shape of Training Data: ', x_train1.shape, x_train2.shape, y_train.shape)\n",
        "print ('Shape of Validation Data', x_val1.shape, x_val2.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxiWrtEXuoJ7",
        "outputId": "aac13287-ccf8-4148-8421-9bb07cb501f0"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Data:  (1000, 300) (1000, 300) (1000, 1)\n",
            "Shape of Validation Data (100, 300) (100, 300) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here Define the model\n",
        "vector1 = Input(shape=(300,), dtype='float32')\n",
        "vector2 = Input(shape=(300,), dtype='float32')\n",
        "BilinearLayer = NeuralTensorLayer(output_dim=32, input_dim=300, \n",
        "                                  activation= 'relu')([vector1, vector2])\n",
        "\n",
        "g = Dense(1)(BilinearLayer)\n",
        "#The g or the output of the modelled function.\n",
        "model = Model(inputs=[vector1, vector2], outputs=[g])\n",
        "\n",
        "#Compile the model\n",
        "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile( loss='mean_squared_error', optimizer=adam)\n",
        "#The summary of the model.\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssnK68owuovX",
        "outputId": "e96aaf21-a529-4fc9-913d-3391213102fd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_35 (InputLayer)          [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " input_36 (InputLayer)          [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " neural_tensor_layer_16 (Neural  (None, 32)          2899500     ['input_35[0][0]',               \n",
            " TensorLayer)                                                     'input_36[0][0]']               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            33          ['neural_tensor_layer_16[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,899,533\n",
            "Trainable params: 2,899,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([x_train1, x_train2], y_train,\n",
        "          batch_size=64, epochs=5,\n",
        "          validation_data=([x_val1, x_val2], y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uGv2VC0uz_k",
        "outputId": "301ebc9b-a704-4f18-d4e2-d7c585250806"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "16/16 [==============================] - 3s 42ms/step - loss: 2638.7971 - val_loss: 0.4192\n",
            "Epoch 2/5\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 3.0053 - val_loss: 0.4253\n",
            "Epoch 3/5\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.3689 - val_loss: 0.4230\n",
            "Epoch 4/5\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.3655 - val_loss: 0.4182\n",
            "Epoch 5/5\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3605 - val_loss: 0.4121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f067469e250>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "SHOYAvffxwwl",
        "outputId": "6c8d99ba-ce23-4461-8f4f-376b0c99c5da"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_8bE3iA_q8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}