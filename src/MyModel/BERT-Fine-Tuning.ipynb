{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/src/MyModel/BERT-Fine-Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Embedding Fine Tuning"
      ],
      "metadata": {
        "id": "gxa6J-lH4jrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Pu3CpB90ga",
        "outputId": "879d55fe-3a67-4da7-8927-2f8514dfc7fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFjx3Xf38J7l",
        "outputId": "473c0af0-e7d3-4b9b-ed4e-24c9b4f55502"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rootdir = '/content/gdrive/MyDrive/Colab Notebooks/Polarity-Subjectivity-Detection/'"
      ],
      "metadata": {
        "id": "suw-3tTbAfrA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Get the GPU device name\n",
        "device = tf.test.gpu_device_name()\n",
        "\n",
        "if 'GPU' in device:\n",
        "  print(f'GPU available : {device}')\n",
        "  device = torch.device('cuda'+device[-2:])\n",
        "else :\n",
        "  device = torch.device(\"cpu\")\n",
        "  raise SystemError(\"GPU not found, use CPU instead\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Tl20NCMY6_xi",
        "outputId": "9d35318a-c01f-47f7-d1b2-57fa92780c35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cd79b30679f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPU not found, use CPU instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m: GPU not found, use CPU instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "p6buUIlod0K5",
        "outputId": "983f09ed-000a-4052-9519-03006c35cffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# loading dataset\n",
        "movie_reviews = pd.read_csv(rootdir+'Datasets/movie_rews_raw.csv')\n",
        "subj_obj_dataset = pd.read_csv(rootdir+'Datasets/subj_obj_dataset_clean.csv')"
      ],
      "metadata": {
        "id": "TZCUmC4h7WEh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mDrScMj7Asm3",
        "outputId": "b2657c48-eba1-402d-f670-74448121ce2e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               text\n",
              "0              0  plot : two teen couples go to a church party ,...\n",
              "1              1  the happy bastard ' s quick movie review damn ...\n",
              "2              2  it is movies like these that make a jaded movi...\n",
              "3              3  \" quest for camelot \" is warner bros . ' first...\n",
              "4              4  synopsis : a mentally unstable man undergoing ...\n",
              "...          ...                                                ...\n",
              "1995        1995  wow ! what a movie . it ' s everything a movie...\n",
              "1996        1996  richard gere can be a commanding actor , but h...\n",
              "1997        1997  glory -- starring matthew broderick , denzel w...\n",
              "1998        1998  steven spielberg ' s second epic film on world...\n",
              "1999        1999  truman ( \" true - man \" ) burbank is the perfe...\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a13b421-1aec-4061-97ca-7f789f5e5258\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the happy bastard ' s quick movie review damn ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\" quest for camelot \" is warner bros . ' first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1995</td>\n",
              "      <td>wow ! what a movie . it ' s everything a movie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1996</td>\n",
              "      <td>richard gere can be a commanding actor , but h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1997</td>\n",
              "      <td>glory -- starring matthew broderick , denzel w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1998</td>\n",
              "      <td>steven spielberg ' s second epic film on world...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1999</td>\n",
              "      <td>truman ( \" true - man \" ) burbank is the perfe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a13b421-1aec-4061-97ca-7f789f5e5258')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a13b421-1aec-4061-97ca-7f789f5e5258 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a13b421-1aec-4061-97ca-7f789f5e5258');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subj_obj_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DujGO_7-AwXH",
        "outputId": "9caa129f-3c93-40ea-a4d0-b3ea00a56a40"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               text\n",
              "0              0  smart and alert , thirteen conversations about...\n",
              "1              1  color , musical bounce and warm seas lapping o...\n",
              "2              2  it is not a mass-market entertainment but an u...\n",
              "3              3  a light-hearted french film about the spiritua...\n",
              "4              4  my wife is an actress has its moments in looki...\n",
              "...          ...                                                ...\n",
              "9995        9995  in the end , they discover that balance in lif...\n",
              "9996        9996  a counterfeit 1000 tomin bank note is passed i...\n",
              "9997        9997  enter the beautiful and mysterious secret agen...\n",
              "9998        9998  after listening to a missionary from china spe...\n",
              "9999        9999  looking for a short cut to fame , glass concoc...\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc5c8a96-68a1-4b7c-872d-e966aee6aa68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>smart and alert , thirteen conversations about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>color , musical bounce and warm seas lapping o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>it is not a mass-market entertainment but an u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a light-hearted french film about the spiritua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>my wife is an actress has its moments in looki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9995</td>\n",
              "      <td>in the end , they discover that balance in lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9996</td>\n",
              "      <td>a counterfeit 1000 tomin bank note is passed i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9997</td>\n",
              "      <td>enter the beautiful and mysterious secret agen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9998</td>\n",
              "      <td>after listening to a missionary from china spe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>9999</td>\n",
              "      <td>looking for a short cut to fame , glass concoc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc5c8a96-68a1-4b7c-872d-e966aee6aa68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc5c8a96-68a1-4b7c-872d-e966aee6aa68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc5c8a96-68a1-4b7c-872d-e966aee6aa68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subjective = subj_obj_dataset[['text','labels']][:len(subj_obj_dataset)//2].sample(n=1000)"
      ],
      "metadata": {
        "id": "G9UOFOzx1_cU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#objective = subj_obj_dataset[['text', 'labels']][len(subj_obj_dataset)//2:].sample(n=1000)"
      ],
      "metadata": {
        "id": "EI6BUx7F4GiC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subj_obj_dataset = pd.concat([subjective,objective], axis=0)"
      ],
      "metadata": {
        "id": "QMXa0AnE5HPf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subj_obj_dataset"
      ],
      "metadata": {
        "id": "LobPS0qV5aXt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjective = subj_obj_dataset[['text']][:len(subj_obj_dataset)//2].sample(n=1000)\n",
        "objective = subj_obj_dataset[['text']][len(subj_obj_dataset)//2:].sample(n=1000)\n",
        "subj_obj_dataset = pd.concat([subjective,objective], axis=0)"
      ],
      "metadata": {
        "id": "4MuNN3oHWaVy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_obj_dataset"
      ],
      "metadata": {
        "id": "SqWi-Gl5Wsx4",
        "outputId": "23644df9-4eb5-47ba-85d2-8640c149f0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text\n",
              "188   the acting is uniformly excellent , with kyra ...\n",
              "2652  crush could be the worst film a man has made a...\n",
              "76    so relentlessly wholesome it made me want to s...\n",
              "2787  dong doesn't demonize the conservative christi...\n",
              "3158  oscar wilde's masterpiece , the importance of ...\n",
              "...                                                 ...\n",
              "9639  he awakes to what appears to be the next morni...\n",
              "9318  a british television personality , terry twill...\n",
              "7666  he soon finds himself plunged into a mystery o...\n",
              "8467  but slowly , their teenage-son alan ( kristian...\n",
              "7121  the company offered \" ice in an hour \" deliver...\n",
              "\n",
              "[2000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c108b102-038e-47b5-8ce7-90a993cc845b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>the acting is uniformly excellent , with kyra ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2652</th>\n",
              "      <td>crush could be the worst film a man has made a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>so relentlessly wholesome it made me want to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2787</th>\n",
              "      <td>dong doesn't demonize the conservative christi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158</th>\n",
              "      <td>oscar wilde's masterpiece , the importance of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9639</th>\n",
              "      <td>he awakes to what appears to be the next morni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9318</th>\n",
              "      <td>a british television personality , terry twill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7666</th>\n",
              "      <td>he soon finds himself plunged into a mystery o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8467</th>\n",
              "      <td>but slowly , their teenage-son alan ( kristian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7121</th>\n",
              "      <td>the company offered \" ice in an hour \" deliver...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c108b102-038e-47b5-8ce7-90a993cc845b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c108b102-038e-47b5-8ce7-90a993cc845b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c108b102-038e-47b5-8ce7-90a993cc845b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Major commands :\n",
        "- .tokenize(sent)\n",
        "- .convert_tokens_to_ids(tokenized_sent)\n",
        "- .encode.plus() [source](https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus)"
      ],
      "metadata": {
        "id": "RnYxmD2FEySp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT model script from: huggingface.co\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from typing import Tuple, List, Dict\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import logging\n",
        "import gc\n",
        "\n",
        "# to not see warning everytime\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)"
      ],
      "metadata": {
        "id": "KuyfsCFkKaSy"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding(dataset : pd.DataFrame, \n",
        "              sentence_column: str, \n",
        "              tokenizer: BertTokenizer, \n",
        "              maxlen: int\n",
        "              ) -> Tuple[torch.Tensor]:  \n",
        "    '''Extract embedding information using passed tokenizer and model\n",
        "        Params:\n",
        "        ------\n",
        "            dataset : pd.DataFrame\n",
        "                dataframe containig sentences to be encoded\n",
        "            sentence_column : str\n",
        "                column in the beforementioned dataframe to be encoded\n",
        "            tokenizer : transformers.models.bert.tokenization_bert.BertTokenizer\n",
        "                tokenizer used to process sentences and extract related information\n",
        "        Return:\n",
        "        ------\n",
        "            Return encodings and attention masks as pytorch tensors\n",
        "    '''\n",
        "    \n",
        "    embeddings = {\n",
        "        'embedding' : [],\n",
        "        'attention_mask' : []\n",
        "        }\n",
        "        \n",
        "    for sent in dataset[sentence_column]:\n",
        "        dic_sent_encoding = tokenizer.encode_plus(sent,              # untokenized sentence\n",
        "                                                add_special_tokens = True,      # add '[CLS]' and '[SEP]'\n",
        "                                                truncation = True,              # truncate to maximum length\n",
        "                                                max_length = maxlen,            # due to ram limiatation \n",
        "                                                padding = \"max_length\",         # pad to maximum admissible sentence\n",
        "                                                return_attention_mask = True,   # return attention mask\n",
        "                                                return_tensors = \"pt\")          # returns pytorch tensors\n",
        "    \n",
        "        # extracting embeddings and attention masks in list form\n",
        "        embeddings['embedding'].append(dic_sent_encoding['input_ids'])\n",
        "        embeddings['attention_mask'].append(dic_sent_encoding['attention_mask'])\n",
        "\n",
        "    # convert lists of tensors into tensors\n",
        "    #input_ids = torch.cat(embeddings['embedding'], axis=0)\n",
        "    #attention_masks = torch.cat(embeddings['attention_mask'], axis=0)\n",
        "    \n",
        "    #return input_ids, attention_masks\n",
        "    return embeddings['embedding'], embeddings['attention_mask']"
      ],
      "metadata": {
        "id": "I1Ov7l-CAyG6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mr_encoding, attention_masks_mr = embedding(dataset=movie_reviews, sentence_column='text', tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "bslSQQ1VagQf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to display a sample tensor uncomment following lines\n",
        "#mr_encoding[0], attention_masks_mr[0]"
      ],
      "metadata": {
        "id": "0Wa8BAy3SaQp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so_encoding, attention_masks_so = embedding(dataset=subj_obj_dataset, sentence_column='text', tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "A_RI20fmM0JW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to display a sample tensor uncomment following lines\n",
        "#so_encoding[0], attention_masks_so[0]"
      ],
      "metadata": {
        "id": "QmB8kLzASrTR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to investigate size of a tensor uncomment following lones\n",
        "#so_encoding[0].size(), attention_masks_so[0].size()"
      ],
      "metadata": {
        "id": "LCs25QfZTYpX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BATCH_SIZE = 128 # reduced due to RAM limitations"
      ],
      "metadata": {
        "id": "uNy-pqdEnS-h"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddings(dataset: pd.DataFrame, \n",
        "               tokenizer: BertTokenizer, \n",
        "               model: BertModel, \n",
        "               maxlen: int, \n",
        "               column_name: str='text',\n",
        "               device: str=device\n",
        "               )-> List:\n",
        "    '''Function to batch sentences to fit BERT model and get embeddings\n",
        "\n",
        "        Params:\n",
        "        ------\n",
        "            dataset : pd.DataFrame\n",
        "                dataset to be batched\n",
        "            column_name : str\n",
        "                column of 'dataset' DataFrame to catch \n",
        "        \n",
        "        Return:\n",
        "        ------\n",
        "            tuple of dataloader to iterate over\n",
        "    '''\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    embs = []\n",
        "    # getting encodings and attention masks for whole dataset\n",
        "    emb, msk = embedding(dataset=dataset, sentence_column=column_name, tokenizer=tokenizer, maxlen=maxlen)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for e in zip(emb,msk):\n",
        "            last_hidden_states = model(e[0].to(device),e[1].to(device))\n",
        "            #print(last_hidden_states[0].shape)\n",
        "            embs.append(last_hidden_states[0])\n",
        "\n",
        "    return embs"
      ],
      "metadata": {
        "id": "16S6YJ7wnBZ5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "def clear_folder_content(folder):\n",
        "    for filename in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ],
      "metadata": {
        "id": "0gv_QzUzQxP5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_folder_content(rootdir+'BERT/Polarity-Embeddings')\n",
        "clear_folder_content(rootdir+'BERT/Subjectivity-Embeddings')"
      ],
      "metadata": {
        "id": "LkJR3L-WbJk5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_folder_content(rootdir+'BERT/Polarity-Embeddings-Truncated')\n",
        "clear_folder_content(rootdir+'BERT/Subjectivity-Embeddings-Truncated')"
      ],
      "metadata": {
        "id": "xNY4e6GxTfAZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_folder_content(rootdir+'BERT/Subjectivity-Embeddings-Truncated-Raw')\n",
        "clear_folder_content(rootdir+'BERT/Subjectivity-Embeddings-Truncated-Raw')"
      ],
      "metadata": {
        "id": "qKVv1s6lButM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_embs(embs: List[torch.Tensor], dest_folder: str, kind: str) -> None:\n",
        "    for i in range(20):\n",
        "        to_save = []\n",
        "        data = embs[i*100:(i+1)*100]\n",
        "        #print(f\"{i}, {data}\\n\")\n",
        "        #print(\"=============================================================\\n\")\n",
        "        #print(len(data))\n",
        "        for b in data: # getting one tensor at a time -> embs[i]\n",
        "            #for s in b: # to have (512x768)\n",
        "                #print(f\"Print s {s} \\n\")\n",
        "            to_save.append(b[0].cpu().numpy())\n",
        "        np.save(rootdir+'BERT/{}/bert_emb_{}_{}.npy'.format(dest_folder, kind, (i+1)*100), to_save)"
      ],
      "metadata": {
        "id": "tPpBF7fcNhY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mr_embs = embeddings(dataset=movie_reviews, tokenizer=tokenizer, model=model, maxlen=45)"
      ],
      "metadata": {
        "id": "aAjWkH_8XCKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "g-Xzdt8N1yfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_embs = embeddings(dataset=subj_obj_dataset, tokenizer=tokenizer, model=model, maxlen=45)"
      ],
      "metadata": {
        "id": "JXE6ua4FfjSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(mr_embs))"
      ],
      "metadata": {
        "id": "mQpaW6KyaP5X",
        "outputId": "d80fce39-77a6-44b9-cb98-9a13fe2b10a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mr_embs[0].size()"
      ],
      "metadata": {
        "id": "3PGEAkAPaYSD",
        "outputId": "08aff72c-24a7-4af9-a99c-5d79f54ae657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 45, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mr_embs[0][0].size()"
      ],
      "metadata": {
        "id": "Lqm6vFQJacmC",
        "outputId": "7b2371c4-d71f-4854-9b53-13f51b6d3afe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([45, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mr_embs[0][0] == mr_embs[0]"
      ],
      "metadata": {
        "id": "cTXcddwnaiKw",
        "outputId": "d896c86b-3990-4d4b-d896-7727ac952bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         ...,\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_embs(embs=mr_embs, dest_folder='Polarity-Embeddings-Truncated-Raw', kind='pol')"
      ],
      "metadata": {
        "id": "heSvGXmY3sF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embs(embs=subj_embs, dest_folder='Subjectivity-Embeddings-Truncated-Raw', kind='subj')"
      ],
      "metadata": {
        "id": "mXbO_f8S33NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_emb_100 = np.load(rootdir+'BERT/Polarity-Embeddings-Truncated/bert_emb_pol_100.npy')\n",
        "bert_emb_200 = np.load(rootdir+'BERT/Polarity-Embeddings-Truncated/bert_emb_pol_200.npy')"
      ],
      "metadata": {
        "id": "1bRWz5nupX8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_emb_100.shape"
      ],
      "metadata": {
        "id": "5Kkqfe00Z-1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_emb_200.shape"
      ],
      "metadata": {
        "id": "yUFdrYMDaLco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_emb_100[:5]==bert_emb_200[:5]"
      ],
      "metadata": {
        "id": "jZ9XoG6vg0Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "iQWu_AXR756n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unused"
      ],
      "metadata": {
        "id": "edofTPWuUwUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ids_dataloader, _ = batching_data(dataset=movie_reviews, tokenizer=tokenizer)\n",
        "#for idx, ids in enumerate(ids_dataloader):\n",
        "#    print(idx, ids, len(ids))\n",
        "#    if idx==2:\n",
        "#        break"
      ],
      "metadata": {
        "id": "W1PnRA0lp9aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding taken from last layer of BERT\n",
        "# avoid touching and computing gradients -> torch.no_grad()\n",
        "# https://towardsdatascience.com/what-is-npy-files-and-why-you-should-use-them-603373c78883\n",
        "\n",
        "def fine_tune_BERT( model: BertModel, dataset: pd.DataFrame, tokenizer: BertTokenizer,\n",
        "                   sentence_column: str='text', batch_size: int=BATCH_SIZE, \n",
        "                   device: str=device, rootdir: str=rootdir, filename: str='pol') -> List[torch.Tensor]:\n",
        "    \"\"\"Return Embeddings of dataset\n",
        "\n",
        "        Params:\n",
        "        ------\n",
        "            model: transformers.models.bert.modeling_bert.BertModel\n",
        "                BertModel to get embeddings from\n",
        "            dataset : pd.Dataframe\n",
        "                dataframe containing sentences to embed\n",
        "            tokenizer : transformers.models.bert.tokenization_bert.BertTokenizer\n",
        "                tokenizer model to use\n",
        "            sentence_column : str\n",
        "                column of 'dataset' to get\n",
        "            batch_size : int\n",
        "                batch size\n",
        "            device : str\n",
        "                device to load data on\n",
        "            rootdir : str\n",
        "                root directory where to store embeddings\n",
        "            filename : str\n",
        "                name on which saving embeddings\n",
        "        \n",
        "        Return:\n",
        "        ------\n",
        "            List of embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    embs = []\n",
        "    # getting dataloaders\n",
        "    ids_dataloader, msk_dataloader = batching_data(dataset=dataset, tokenizer=tokenizer, batch_size=batch_size)\n",
        "    # disabling gradients computation --> I'm using a pre-trained net. Don't want to rewrite weights\n",
        "    with torch.no_grad():\n",
        "        # iterating through batches\n",
        "        for idx, (ids,msk) in enumerate(zip(ids_dataloader,msk_dataloader)):\n",
        "\n",
        "            # move data to device \n",
        "            ids = ids.to(device)\n",
        "            msk = msk.to(device)\n",
        "\n",
        "            # 'forward pass'\n",
        "            outputs = model(ids,msk)\n",
        "\n",
        "            # extracting tensor at last layer : https://github.com/esrel/NLU.Lab.2022.Public/blob/master/notebooks/10_sequence_nn.ipynb\n",
        "            last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "            print(f\"Done batch #{idx}\")\n",
        "            print(last_hidden_state.cpu().numpy().shape)\n",
        "            embs.append(last_hidden_state)\n",
        "        if len(embs)>0:\n",
        "            print('Embs list has been successfully built')\n",
        "        else:\n",
        "            raise ValueError('List has not been filled')\n",
        "\n",
        "    return embs"
      ],
      "metadata": {
        "id": "2qYdI6k4Qir3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subj_obj_embs = np.load(rootdir+'subj_obj_10000.npy')\n",
        "#for i in range(1000, 11000, 1000):\n",
        "#    subj_obj_embs = np.concatenate((subj_obj_embs, np.load(rootdir+f'subj_obj_{i}.npy')), axis=0)\n",
        "\n",
        "#save_embs(dataset=subj_obj_embs, filename='subj_obj_embs.npy')"
      ],
      "metadata": {
        "id": "wdoXzX1pxvqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_embs(embs=embs_per_batch_subj_obj, filename='subj_obj.npy')"
      ],
      "metadata": {
        "id": "XTgTB31ljeLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subj_obj = {}\n",
        "\n",
        "# 64*15+40 = 1000\n",
        "#for i in range(1000,11000,1000):\n",
        "    #subj_obj[str(i)] = subj_obj_dataset[i-1000:i]\n",
        "    #embs_per_batch_subj_obj = fine_tune_BERT(model=model, dataset=subj_obj_dataset[i-1000:i], tokenizer=tokenizer)\n",
        "    #save_embs(embs_per_batch_subj_obj, f'subj_obj_{i}.npy')"
      ],
      "metadata": {
        "id": "ozLXZGFdubXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_embs(embs=mr_embs, filename='pol_embs.npy')"
      ],
      "metadata": {
        "id": "SK-f7LrcFVQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_embs(embs=subj_embs, filename='subj_obj_embs.npy')"
      ],
      "metadata": {
        "id": "LlHUeyek7S5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}