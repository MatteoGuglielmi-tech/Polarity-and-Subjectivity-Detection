{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHgomvrHLIsiVmVDqheibZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "380f33ff05ca4d92822cf147f6545aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ed1f054fba14623b13c64671361aba5",
              "IPY_MODEL_565a67c3b2294d87b4675762d1e17f22",
              "IPY_MODEL_1c0d2a87ca13421186f3296199fe5f80"
            ],
            "layout": "IPY_MODEL_220e7540066c43f185430a1ea1db9bed"
          }
        },
        "8ed1f054fba14623b13c64671361aba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d992292ca5f542b3b44d529aa0fef30f",
            "placeholder": "​",
            "style": "IPY_MODEL_d12ab3570d99498cbc8b6ae500eb9b05",
            "value": ""
          }
        },
        "565a67c3b2294d87b4675762d1e17f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa2e4fb1457249e69d943d8a8da5089b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85b31c4249cc40fba8953e6e53ca30de",
            "value": 0
          }
        },
        "1c0d2a87ca13421186f3296199fe5f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571a276122a44fa787d737a61ef7ba60",
            "placeholder": "​",
            "style": "IPY_MODEL_bc31fedf8958440c820378ac32aae618",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "220e7540066c43f185430a1ea1db9bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d992292ca5f542b3b44d529aa0fef30f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12ab3570d99498cbc8b6ae500eb9b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa2e4fb1457249e69d943d8a8da5089b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "85b31c4249cc40fba8953e6e53ca30de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "571a276122a44fa787d737a61ef7ba60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc31fedf8958440c820378ac32aae618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/src/MyModel/BERT-Fine-Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Embedding Fine Tuning"
      ],
      "metadata": {
        "id": "gxa6J-lH4jrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Pu3CpB90ga",
        "outputId": "bfbba04a-9ebc-4243-fe6e-42020c9a2513"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFjx3Xf38J7l",
        "outputId": "a4f91cd9-a238-4c80-bce6-64832d8864e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rootdir = '/content/gdrive/MyDrive/Colab Notebooks/Polarity-Subjectivity-Detection/'"
      ],
      "metadata": {
        "id": "suw-3tTbAfrA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Get the GPU device name\n",
        "device = tf.test.gpu_device_name()\n",
        "\n",
        "if 'GPU' in device:\n",
        "  print(f'GPU available : {device}')\n",
        "  device = torch.device('cuda'+device[-2:])\n",
        "else :\n",
        "  device = torch.device(\"cpu\")\n",
        "  raise SystemError(\"GPU not found, use CPU instead\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl20NCMY6_xi",
        "outputId": "cbc66d12-8edc-492a-a5a0-dc5b60c30088"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available : /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6buUIlod0K5",
        "outputId": "b000218a-9f97-47b1-818a-c5a5912155b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# loading dataset\n",
        "movie_reviews = pd.read_csv(rootdir+'movie_rews.csv')\n",
        "subj_obj_dataset = pd.read_csv(rootdir+'subj_obj_dataset.csv')"
      ],
      "metadata": {
        "id": "TZCUmC4h7WEh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mDrScMj7Asm3",
        "outputId": "99c9461d-5069-4d63-b504-fd1491d35146"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               text  labels\n",
              "0              0  films adapted comic books plenty success wheth...       1\n",
              "1              1  every movie comes along suspect studio every i...       1\n",
              "2              2  got mail works alot better deserves order make...       1\n",
              "3              3  jaws rare film grabs attention shows single im...       1\n",
              "4              4  moviemaking lot like general manager nfl team ...       1\n",
              "...          ...                                                ...     ...\n",
              "1995        1995  anything stigmata taken warning releasing simi...       0\n",
              "1996        1996  john boorman zardoz goofy cinematic debacle fu...       0\n",
              "1997        1997  kids hall acquired taste took least season wat...       0\n",
              "1998        1998  time john carpenter great horror director cour...       0\n",
              "1999        1999  two party guys bob heads haddaway dance hit lo...       0\n",
              "\n",
              "[2000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ddb2da6-293a-4f66-ad5d-40d98af47bbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>films adapted comic books plenty success wheth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>every movie comes along suspect studio every i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>got mail works alot better deserves order make...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>jaws rare film grabs attention shows single im...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>moviemaking lot like general manager nfl team ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1995</td>\n",
              "      <td>anything stigmata taken warning releasing simi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1996</td>\n",
              "      <td>john boorman zardoz goofy cinematic debacle fu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1997</td>\n",
              "      <td>kids hall acquired taste took least season wat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1998</td>\n",
              "      <td>time john carpenter great horror director cour...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1999</td>\n",
              "      <td>two party guys bob heads haddaway dance hit lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ddb2da6-293a-4f66-ad5d-40d98af47bbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ddb2da6-293a-4f66-ad5d-40d98af47bbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ddb2da6-293a-4f66-ad5d-40d98af47bbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subj_obj_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DujGO_7-AwXH",
        "outputId": "2c0cd6d6-36ea-4268-cac4-f501bfeb89f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               text  labels\n",
              "0              0  smart and alert , thirteen conversations about...       1\n",
              "1              1  color , musical bounce and warm seas lapping o...       1\n",
              "2              2  it is not a mass-market entertainment but an u...       1\n",
              "3              3  a light-hearted french film about the spiritua...       1\n",
              "4              4  my wife is an actress has its moments in looki...       1\n",
              "...          ...                                                ...     ...\n",
              "9995        9995  in the end , they discover that balance in lif...       0\n",
              "9996        9996  a counterfeit 1000 tomin bank note is passed i...       0\n",
              "9997        9997  enter the beautiful and mysterious secret agen...       0\n",
              "9998        9998  after listening to a missionary from china spe...       0\n",
              "9999        9999  looking for a short cut to fame , glass concoc...       0\n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-416e7f17-38fd-4b75-85f9-c06d597dc5ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>smart and alert , thirteen conversations about...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>color , musical bounce and warm seas lapping o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>it is not a mass-market entertainment but an u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a light-hearted french film about the spiritua...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>my wife is an actress has its moments in looki...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9995</td>\n",
              "      <td>in the end , they discover that balance in lif...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9996</td>\n",
              "      <td>a counterfeit 1000 tomin bank note is passed i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9997</td>\n",
              "      <td>enter the beautiful and mysterious secret agen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9998</td>\n",
              "      <td>after listening to a missionary from china spe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>9999</td>\n",
              "      <td>looking for a short cut to fame , glass concoc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-416e7f17-38fd-4b75-85f9-c06d597dc5ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-416e7f17-38fd-4b75-85f9-c06d597dc5ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-416e7f17-38fd-4b75-85f9-c06d597dc5ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subjective = subj_obj_dataset[['text','labels']][:len(subj_obj_dataset)//2].sample(n=1000)"
      ],
      "metadata": {
        "id": "G9UOFOzx1_cU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objective = subj_obj_dataset[['text', 'labels']][len(subj_obj_dataset)//2:].sample(n=1000)"
      ],
      "metadata": {
        "id": "EI6BUx7F4GiC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_obj_dataset = pd.concat([subjective,objective], axis=0)"
      ],
      "metadata": {
        "id": "QMXa0AnE5HPf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_obj_dataset"
      ],
      "metadata": {
        "id": "LobPS0qV5aXt",
        "outputId": "11b70776-16a0-4dc5-e738-75d7450fb5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  labels\n",
              "3050  in gleefully , thumpingly hyperbolic terms , i...       1\n",
              "3538  the first half bursts with a goofy energy prev...       1\n",
              "2225  the last kiss will probably never achieve the ...       1\n",
              "3984  if this dud had been made in the '70s , it wou...       1\n",
              "1802  watching queen of the damned is like reading a...       1\n",
              "...                                                 ...     ...\n",
              "7372  stands paralyzed , and she is only saved by th...       0\n",
              "7212  when the singing veggies encounter some car tr...       0\n",
              "6172  on their way back , they drive through death v...       0\n",
              "5781  before the gang returns , jack and erin's conn...       0\n",
              "6804  the jew ( shylock ) has a long memory of oppre...       0\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01da734-2d47-4fd6-9065-4ba3e43ddd6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>in gleefully , thumpingly hyperbolic terms , i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>the first half bursts with a goofy energy prev...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2225</th>\n",
              "      <td>the last kiss will probably never achieve the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3984</th>\n",
              "      <td>if this dud had been made in the '70s , it wou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802</th>\n",
              "      <td>watching queen of the damned is like reading a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7372</th>\n",
              "      <td>stands paralyzed , and she is only saved by th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7212</th>\n",
              "      <td>when the singing veggies encounter some car tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6172</th>\n",
              "      <td>on their way back , they drive through death v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5781</th>\n",
              "      <td>before the gang returns , jack and erin's conn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6804</th>\n",
              "      <td>the jew ( shylock ) has a long memory of oppre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01da734-2d47-4fd6-9065-4ba3e43ddd6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a01da734-2d47-4fd6-9065-4ba3e43ddd6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a01da734-2d47-4fd6-9065-4ba3e43ddd6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Major commands :\n",
        "- .tokenize(sent)\n",
        "- .convert_tokens_to_ids(tokenized_sent)\n",
        "- .encode.plus() [source](https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus)"
      ],
      "metadata": {
        "id": "RnYxmD2FEySp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT model script from: huggingface.co\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from typing import Tuple, List, Dict\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import logging\n",
        "import gc\n",
        "\n",
        "# to not see warning everytime\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)"
      ],
      "metadata": {
        "id": "KuyfsCFkKaSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "380f33ff05ca4d92822cf147f6545aa9",
            "8ed1f054fba14623b13c64671361aba5",
            "565a67c3b2294d87b4675762d1e17f22",
            "1c0d2a87ca13421186f3296199fe5f80",
            "220e7540066c43f185430a1ea1db9bed",
            "d992292ca5f542b3b44d529aa0fef30f",
            "d12ab3570d99498cbc8b6ae500eb9b05",
            "fa2e4fb1457249e69d943d8a8da5089b",
            "85b31c4249cc40fba8953e6e53ca30de",
            "571a276122a44fa787d737a61ef7ba60",
            "bc31fedf8958440c820378ac32aae618"
          ]
        },
        "outputId": "9ec9d61f-103d-4bbb-9bcc-5fb9656c8ae8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "380f33ff05ca4d92822cf147f6545aa9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FmCxeBsaD0",
        "outputId": "92c50cae-5a09-4788-a391-92732ca872f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bert.modeling_bert.BertModel"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer)"
      ],
      "metadata": {
        "id": "jXKC7c1-9-Zw",
        "outputId": "8d9192a4-7150-4f9a-a27c-7b5cb7c229bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bert.tokenization_bert.BertTokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding(dataset : pd.DataFrame, sentence_column: str, tokenizer: BertTokenizer) -> Tuple[torch.Tensor]:  # Tuple[List]:\n",
        "    '''Extract embedding information using passed tokenizer and model\n",
        "        Params:\n",
        "        ------\n",
        "            dataset : pd.DataFrame\n",
        "                dataframe containig sentences to be encoded\n",
        "            sentence_column : str\n",
        "                column in the beforementioned dataframe to be encoded\n",
        "            tokenizer : transformers.models.bert.tokenization_bert.BertTokenizer\n",
        "                tokenizer used to process sentences and extract related information\n",
        "        Return:\n",
        "        ------\n",
        "            Return encodings and attention masks as pytorch tensors\n",
        "    '''\n",
        "    \n",
        "    embeddings = {\n",
        "        'embedding' : [],\n",
        "        'attention_mask' : []\n",
        "        }\n",
        "        \n",
        "    for sent in dataset[sentence_column]:\n",
        "        dic_sent_encoding = tokenizer.encode_plus(sent, # untokenized sentence\n",
        "                                                add_special_tokens = True,  # add '[CLS]' and '[SEP]'\n",
        "                                                truncation = True,  # truncate to maximum length\n",
        "                                                padding = \"max_length\",  # pad to maximum admissible sentence\n",
        "                                                return_attention_mask = True,  # return attention mask\n",
        "                                                return_tensors = \"pt\") # returns pytorch tensors\n",
        "    \n",
        "        # extracting embeddings and attention masks in list form\n",
        "        embeddings['embedding'].append(dic_sent_encoding['input_ids'])\n",
        "        embeddings['attention_mask'].append(dic_sent_encoding['attention_mask'])\n",
        "\n",
        "    # convert lists of tensors into tensors\n",
        "    #input_ids = torch.cat(embeddings['embedding'], axis=0)\n",
        "    #attention_masks = torch.cat(embeddings['attention_mask'], axis=0)\n",
        "    \n",
        "    #return input_ids, attention_masks\n",
        "    return embeddings['embedding'], embeddings['attention_mask']\n",
        "    #return dic_sent_encoding"
      ],
      "metadata": {
        "id": "I1Ov7l-CAyG6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mr_encoding, attention_masks_mr = embedding(dataset=movie_reviews, sentence_column='text', tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "bslSQQ1VagQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to display a sample tensor uncomment following lines\n",
        "#mr_encoding[0], attention_masks_mr[0]"
      ],
      "metadata": {
        "id": "0Wa8BAy3SaQp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so_encoding, attention_masks_so = embedding(dataset=subj_obj_dataset, sentence_column='text', tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "A_RI20fmM0JW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to display a sample tensor uncomment following lines\n",
        "#so_encoding[0], attention_masks_so[0]"
      ],
      "metadata": {
        "id": "QmB8kLzASrTR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to investigate size of a tensor uncomment following lones\n",
        "#so_encoding[0].size(), attention_masks_so[0].size()"
      ],
      "metadata": {
        "id": "LCs25QfZTYpX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BATCH_SIZE = 128 # reduced due to RAM limitations"
      ],
      "metadata": {
        "id": "uNy-pqdEnS-h"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddings(dataset: pd.DataFrame, tokenizer: BertTokenizer, column_name: str='text')-> List:\n",
        "    '''Function to batch sentences to fit BERT model and get embeddings\n",
        "\n",
        "        Params:\n",
        "        ------\n",
        "            dataset : pd.DataFrame\n",
        "                dataset to be batched\n",
        "            column_name : str\n",
        "                column of 'dataset' DataFrame to catch \n",
        "        \n",
        "        Return:\n",
        "        ------\n",
        "            tuple of dataloader to iterate over\n",
        "    '''\n",
        "    embs = []\n",
        "    # getting encodings and attention masks for whole dataset\n",
        "    emb, msk = embedding(dataset=dataset, sentence_column=column_name, tokenizer=tokenizer)\n",
        "\n",
        "    # defining DataLoader that batches ids randomly\n",
        "    #emb_dataloader = DataLoader(dataset=emb, batch_size=batch_size, shuffle=False)\n",
        "    with torch.no_grad():\n",
        "        for e in zip(emb,msk):\n",
        "            last_hidden_states = model(e[0].to(device),e[1].to(device))\n",
        "            #print(last_hidden_states[0].shape)\n",
        "            embs.append(last_hidden_states[0])\n",
        "\n",
        "\n",
        "    # defining DataLoader that batches masks\n",
        "    #msk_dataloader = DataLoader(dataset=msk, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    #return ids_dataloader, msk_dataloader\n",
        "    return embs"
      ],
      "metadata": {
        "id": "16S6YJ7wnBZ5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_embs(embs: List[torch.Tensor], filename: str) -> None:\n",
        "    # collecting all embeddings together\n",
        "    # each element of the list is a list of tensors concerning each batch\n",
        "    to_save = []\n",
        "    for b in embs: # getting one tensor at a time -> embs[i]\n",
        "        #for gs in b: # getting the t-th sample -> embs[i][t]\n",
        "        for s in b:\n",
        "            # s is a tensor now\n",
        "            to_save.append(s.cpu().numpy())\n",
        "    \n",
        "    np.save(rootdir+filename, to_save)"
      ],
      "metadata": {
        "id": "tPpBF7fcNhY9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mr_embs = embeddings(movie_reviews, tokenizer)"
      ],
      "metadata": {
        "id": "aAjWkH_8XCKM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_embs = embeddings(subj_obj_dataset, tokenizer)"
      ],
      "metadata": {
        "id": "JXE6ua4FfjSQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-Xzdt8N1yfU",
        "outputId": "58f32c7c-90b0-4924-9726-4e1166820575"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_embs(embs=mr_embs, filename='pol_embs.npy')"
      ],
      "metadata": {
        "id": "SK-f7LrcFVQh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_embs(embs=subj_embs, filename='subj_obj_embs.npy')"
      ],
      "metadata": {
        "id": "LlHUeyek7S5_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.cuda.empty_cache()\n",
        "#gc.collect()"
      ],
      "metadata": {
        "id": "iQWu_AXR756n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unused"
      ],
      "metadata": {
        "id": "edofTPWuUwUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ids_dataloader, _ = batching_data(dataset=movie_reviews, tokenizer=tokenizer)\n",
        "#for idx, ids in enumerate(ids_dataloader):\n",
        "#    print(idx, ids, len(ids))\n",
        "#    if idx==2:\n",
        "#        break"
      ],
      "metadata": {
        "id": "W1PnRA0lp9aV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding taken from last layer of BERT\n",
        "# avoid touching and computing gradients -> torch.no_grad()\n",
        "# https://towardsdatascience.com/what-is-npy-files-and-why-you-should-use-them-603373c78883\n",
        "\n",
        "def fine_tune_BERT( model: BertModel, dataset: pd.DataFrame, tokenizer: BertTokenizer,\n",
        "                   sentence_column: str='text', batch_size: int=BATCH_SIZE, \n",
        "                   device: str=device, rootdir: str=rootdir, filename: str='pol') -> List[torch.Tensor]:\n",
        "    \"\"\"Return Embeddings of dataset\n",
        "\n",
        "        Params:\n",
        "        ------\n",
        "            model: transformers.models.bert.modeling_bert.BertModel\n",
        "                BertModel to get embeddings from\n",
        "            dataset : pd.Dataframe\n",
        "                dataframe containing sentences to embed\n",
        "            tokenizer : transformers.models.bert.tokenization_bert.BertTokenizer\n",
        "                tokenizer model to use\n",
        "            sentence_column : str\n",
        "                column of 'dataset' to get\n",
        "            batch_size : int\n",
        "                batch size\n",
        "            device : str\n",
        "                device to load data on\n",
        "            rootdir : str\n",
        "                root directory where to store embeddings\n",
        "            filename : str\n",
        "                name on which saving embeddings\n",
        "        \n",
        "        Return:\n",
        "        ------\n",
        "            List of embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    embs = []\n",
        "    # getting dataloaders\n",
        "    ids_dataloader, msk_dataloader = batching_data(dataset=dataset, tokenizer=tokenizer, batch_size=batch_size)\n",
        "    # disabling gradients computation --> I'm using a pre-trained net. Don't want to rewrite weights\n",
        "    with torch.no_grad():\n",
        "        # iterating through batches\n",
        "        for idx, (ids,msk) in enumerate(zip(ids_dataloader,msk_dataloader)):\n",
        "\n",
        "            # move data to device \n",
        "            ids = ids.to(device)\n",
        "            msk = msk.to(device)\n",
        "\n",
        "            # 'forward pass'\n",
        "            outputs = model(ids,msk)\n",
        "\n",
        "            # extracting tensor at last layer : https://github.com/esrel/NLU.Lab.2022.Public/blob/master/notebooks/10_sequence_nn.ipynb\n",
        "            last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "            print(f\"Done batch #{idx}\")\n",
        "            print(last_hidden_state.cpu().numpy().shape)\n",
        "            embs.append(last_hidden_state)\n",
        "        if len(embs)>0:\n",
        "            print('Embs list has been successfully built')\n",
        "        else:\n",
        "            raise ValueError('List has not been filled')\n",
        "\n",
        "    return embs"
      ],
      "metadata": {
        "id": "2qYdI6k4Qir3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "4402f687-1b6c-41ff-ff3a-0b2e769ca656"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0f5f7fc12259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m def fine_tune_BERT( model: BertModel, dataset: pd.DataFrame, tokenizer: BertTokenizer,\n\u001b[0;32m----> 6\u001b[0;31m                    \u001b[0msentence_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                    device: str=device, rootdir: str=rootdir, filename: str='pol') -> List[torch.Tensor]:\n\u001b[1;32m      8\u001b[0m     \"\"\"Return Embeddings of dataset\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subj_obj_embs = np.load(rootdir+'subj_obj_10000.npy')\n",
        "#for i in range(1000, 11000, 1000):\n",
        "#    subj_obj_embs = np.concatenate((subj_obj_embs, np.load(rootdir+f'subj_obj_{i}.npy')), axis=0)\n",
        "\n",
        "#save_embs(dataset=subj_obj_embs, filename='subj_obj_embs.npy')"
      ],
      "metadata": {
        "id": "wdoXzX1pxvqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_embs(embs=embs_per_batch_subj_obj, filename='subj_obj.npy')"
      ],
      "metadata": {
        "id": "XTgTB31ljeLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subj_obj = {}\n",
        "\n",
        "# 64*15+40 = 1000\n",
        "#for i in range(1000,11000,1000):\n",
        "    #subj_obj[str(i)] = subj_obj_dataset[i-1000:i]\n",
        "    #embs_per_batch_subj_obj = fine_tune_BERT(model=model, dataset=subj_obj_dataset[i-1000:i], tokenizer=tokenizer)\n",
        "    #save_embs(embs_per_batch_subj_obj, f'subj_obj_{i}.npy')"
      ],
      "metadata": {
        "id": "ozLXZGFdubXG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}