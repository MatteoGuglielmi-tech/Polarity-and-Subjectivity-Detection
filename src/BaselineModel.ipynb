{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/src/BaselineModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BL23jCIb5M1"
      },
      "source": [
        "# Baseline model:\n",
        "The baseline is obtained exploiting a Multinomial Naive Bayes classifier. \n",
        "The actual code is partialy taken from the SA dedicated laboratoy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing modules and dowloading archives\n",
        "The following cell is used to import the necessary modules to achieve a reference accuracy to surpass."
      ],
      "metadata": {
        "id": "mJAqc9m_3HEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import subjectivity\n",
        "import numpy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "from typing import List, Dict, Tuple\n",
        "from nltk.sentiment.util import mark_negation\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TsEo3wPm-RZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dowloading list of punctuation signs from nltk. The former will be used in the preprocessing phase of sentences."
      ],
      "metadata": {
        "id": "HGrQryWs3bD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfO1LQOkb4sr",
        "outputId": "f1237bc1-5a17-4f76-cfd9-6dd74bad2e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dowloading the movie reviews dataset. In this project, this is used as polarity dataset on top of which classification is perfomed."
      ],
      "metadata": {
        "id": "GjnFxbXl3rnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFpyVaMjbyoo",
        "outputId": "adaf8cb9-1f6a-4240-bc84-9f83e692449e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "nltk.download('movie_reviews')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dowloading the sabjectivity dataset, used to recognize whether a specific sentence express a subjective opinion or not."
      ],
      "metadata": {
        "id": "ydd4ezli33Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('subjectivity')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N34WGqr8KO3I",
        "outputId": "ccc872ef-6fdc-4c2b-b6ca-214d3985830b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Package subjectivity is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subjectivity"
      ],
      "metadata": {
        "id": "e2X39geZF156"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subj_negative_marking(sent: List[str]) -> str:\n",
        "    ''' Apply double negation flipping\n",
        "\n",
        "        Parameters :\n",
        "        ------------\n",
        "            sent : list(str)\n",
        "                sentence, organized as listo of words, to which apply double negation flipping\n",
        "        \n",
        "        Return :\n",
        "        ------------\n",
        "            str: \n",
        "                Processed sentence\n",
        "    '''\n",
        "\n",
        "    # https://www.nltk.org/api/nltk.sentiment.util.html#nltk.sentiment.util.mark_negation -> wants a list\n",
        "    negated_doc = mark_negation(sent, double_neg_flip=True)\n",
        "    return \" \".join([w for w in negated_doc])"
      ],
      "metadata": {
        "id": "HAABGn3VE-N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, subjective and objective sentences are fetched and a single corpus is build by concatenating two lists."
      ],
      "metadata": {
        "id": "8Idk7r6K4rnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYC6fTRlcY69"
      },
      "outputs": [],
      "source": [
        "subj_docs = [sent for sent in subjectivity.sents(categories='subj')]\n",
        "obj_docs = [sent for sent in subjectivity.sents(categories='obj')]\n",
        "corp = subj_docs+obj_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The double negation function previously mentioned is applied sentence wise to all the corpus phrases."
      ],
      "metadata": {
        "id": "8WfXT2G24-VM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNf7vsWdcgBq"
      },
      "outputs": [],
      "source": [
        "subj_corpus = [subj_negative_marking(los) for los in corp]\n",
        "subj_labels = numpy.array([1] * len(subj_docs) + [0] * len(obj_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A [Count Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.transform) and a [Naive Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) are initialized. These will be used for :\n",
        "- switching from sentences to ids\n",
        "- from vectors to accuracy \n",
        "respectively."
      ],
      "metadata": {
        "id": "fWPLfXd15Gp0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrGr6nCHcdWN"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "classifier = MultinomialNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following, first the vectorizer is used to tranform each sentence in a vector of ids to be used as input to the classifier to get an accuracy measure. To do so, the [cross_validate](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) method by scikit-learn is used. In this particular case, a 10-fold cross validation is performed.\n",
        "Worth to note here is that through the flag `return_estimato=True`, a dictionary with statistics corresponding to each split is returned. This is exploited to extract the best classifier across all splits."
      ],
      "metadata": {
        "id": "jO84TFbJ5p_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building sparse matrix with count vectors\n",
        "vectors = vectorizer.fit_transform(subj_corpus)\n",
        "\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html -> see return estimator here\n",
        "scores = cross_validate(classifier, vectors, subj_labels, cv=StratifiedKFold(n_splits=10) , scoring=['accuracy'], return_estimator=True)\n",
        "scores"
      ],
      "metadata": {
        "id": "gsxs-s_URUnn",
        "outputId": "ada21ca8-b4b3-4aaa-eab5-f0f25095981f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.00857377, 0.0064671 , 0.00624704, 0.00628352, 0.00633097,\n",
              "        0.00657916, 0.00610042, 0.00703645, 0.00595474, 0.00625515]),\n",
              " 'score_time': array([0.0012002 , 0.00119162, 0.00110888, 0.0009582 , 0.00098848,\n",
              "        0.00110912, 0.00109959, 0.00095105, 0.00093603, 0.00099802]),\n",
              " 'estimator': [MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB(),\n",
              "  MultinomialNB()],\n",
              " 'test_accuracy': array([0.89 , 0.909, 0.919, 0.894, 0.918, 0.912, 0.912, 0.927, 0.896,\n",
              "        0.898])}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier with the highest accuracy across all fits\n",
        "best_est = scores['estimator'][scores[\"test_accuracy\"].argmax()]\n",
        "best_score_idx = scores[\"test_accuracy\"].argmax()\n",
        "print(f\"Chosen {best_est} estimator with peak accuracy of : {scores['test_accuracy'][best_score_idx]}\")"
      ],
      "metadata": {
        "id": "tE2Q11QwBnn9",
        "outputId": "ddcf4b3f-97b8-484b-8006-43c487a41a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen MultinomialNB() estimator with peak accuracy of : 0.927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polarity"
      ],
      "metadata": {
        "id": "ZxUvC0yhF4fl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOzyOWd0LfrR"
      },
      "outputs": [],
      "source": [
        "def pol_negative_marking(doc : List[str]) -> List[str]:\n",
        "    '''\n",
        "        Parameters:\n",
        "        ------------\n",
        "            doc : list[str]\n",
        "                document where each element is a list of strings\n",
        "        Returns :\n",
        "        ------------\n",
        "            str :\n",
        "                document after having applied double negation\n",
        "    '''\n",
        "\n",
        "    flat_doc = [w for sent in doc for w in sent]\n",
        "    negated_doc = mark_negation(flat_doc, double_neg_flip=True)\n",
        "\n",
        "    return \" \".join([w for w in negated_doc])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_objectiveness(doc: List[List[str]],\n",
        "                         labels: List[int],\n",
        "                         vect: CountVectorizer, \n",
        "                         clf: MultinomialNB\n",
        "                         ) -> Tuple[List[str], List[int]]:\n",
        "    ''' This function allow to filter sentences based on the prediction of a classifier.\n",
        "    Only the sentences predicted as belongin to class 1 are kept. In this case class 1\n",
        "    corresponds to \"Subjective\".\n",
        "\n",
        "        Parameters :\n",
        "        ------------\n",
        "            doc : list(list(str))\n",
        "                sentences arranged document-wise\n",
        "            labels : list(int)\n",
        "                corresponding labels of each document\n",
        "            vect : CounterVectorizer\n",
        "                vectorizer used to encode the sentences\n",
        "            clf : MultinomialNB\n",
        "                classifier used to make predictions\n",
        "\n",
        "        Returns :\n",
        "        -----------\n",
        "            df_pol_list : List[str]\n",
        "                list containing all the sentences predicted as label 1\n",
        "            df_pol_label : List[int]\n",
        "                ground truth of the sentences predicted as subjective\n",
        "    '''\n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.transform\n",
        "\n",
        "\n",
        "    original_corpus = [pol_negative_marking(d) for d in doc]\n",
        "    pol_corpus = [vectorizer.transform([pol_negative_marking(d)]) for d in doc]\n",
        "    preds = [clf.predict(sent) for sent in pol_corpus]\n",
        "\n",
        "    df_pol_corpus = pd.DataFrame(original_corpus)\n",
        "    df_pol_labels = pd.DataFrame(labels)\n",
        "    df_pol_pred = pd.DataFrame(preds)\n",
        "\n",
        "    df_pol_corpus.rename(columns={0:'text'}, inplace=True)\n",
        "    df_pol_labels.rename(columns={0:'labels'}, inplace=True)\n",
        "    df_pol_pred.rename(columns={0:'predictions'}, inplace=True)\n",
        "\n",
        "    df_pol = pd.concat([df_pol_corpus, df_pol_labels, df_pol_pred], axis=1)\n",
        "    \n",
        "    df_pol = df_pol.loc[df_pol['predictions'] == 1]\n",
        "    df_pol_list = df_pol.text.values.tolist()\n",
        "    df_pol_label = df_pol.labels.values.tolist()\n",
        "\n",
        "    return df_pol_list, df_pol_label"
      ],
      "metadata": {
        "id": "Ige-bp8QJyEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells, first the polarity dataset is initialized and a new corpus is made by the composition of positive and negative documents. \n",
        "Subsequently, objective sentences are filtered out by exploiting the `filter_objectiveness` function encountered before."
      ],
      "metadata": {
        "id": "s_sG-atD85Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mr = movie_reviews\n",
        "neg = mr.paras(categories='neg')\n",
        "pos = mr.paras(categories='pos')\n",
        "cor = pos+neg\n",
        "pol_labels = numpy.array([0] * len(neg) + [1] * len(pos))"
      ],
      "metadata": {
        "id": "qNDNaTaQF6N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pol_list, df_pol_labels = filter_objectiveness(cor, pol_labels, vectorizer, best_est)"
      ],
      "metadata": {
        "id": "Cl2xHvyeO85-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, a brand new vectorizer and a new classifier are instantiated to act upon the pre-processed `movie_reviews` dataset."
      ],
      "metadata": {
        "id": "1rFgJEYX9eFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiating a new vectorizer and classifier\n",
        "pol_vec = CountVectorizer()\n",
        "pol_clf = MultinomialNB()"
      ],
      "metadata": {
        "id": "ehRGikFydcy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pol_vectors = pol_vec.fit_transform(df_pol_list)"
      ],
      "metadata": {
        "id": "-QsUtBpCdlFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last but not least, analogously as for subjectivity classification, a 10-fold cross-validation is performed to assess the preformances of the model.  \n",
        "As final result, the average polarity classification accuracy across the 10 splits is `83.2%`."
      ],
      "metadata": {
        "id": "wSiTAOA69vOr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0L1ImdNch1s",
        "outputId": "90cb2946-25fa-4b6e-d2a6-999ab152a274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline : 0.832 ACC\n"
          ]
        }
      ],
      "source": [
        "# 10-fold cross-validation\n",
        "scores = cross_validate(pol_clf, pol_vectors, df_pol_labels, cv=StratifiedKFold(n_splits=10), scoring=['accuracy'])\n",
        "average = sum(scores['test_accuracy'])/len(scores['test_accuracy'])\n",
        "print(f\"Baseline : {round(average,3)} ACC\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "eV8aDDuvn8fk",
        "outputId": "83e2a131-59ec-43b1-8176-0a509597e02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.01343441, 0.01329398, 0.01235533, 0.01247168, 0.01263618,\n",
              "        0.01244569, 0.01235318, 0.01167965, 0.01576948, 0.01191378]),\n",
              " 'score_time': array([0.00180697, 0.00170159, 0.0016439 , 0.00173092, 0.001791  ,\n",
              "        0.00163269, 0.0017693 , 0.00168014, 0.00168777, 0.00161529]),\n",
              " 'test_accuracy': array([0.78343949, 0.84076433, 0.85987261, 0.89808917, 0.8089172 ,\n",
              "        0.8089172 , 0.82802548, 0.85350318, 0.78846154, 0.84615385])}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['test_accuracy'].mean()"
      ],
      "metadata": {
        "id": "wpR0_-bVn9Xu",
        "outputId": "b112d008-ac3d-4ab8-df5e-8182b3956826",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8316144047035767"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['test_accuracy'].std()**2"
      ],
      "metadata": {
        "id": "K_FCUT2NoBXn",
        "outputId": "f67c82b5-74ab-455e-e175-373fdf0231fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0011217855195825128"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Subjectivity_and_Polarity_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}