{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdlKn0FkE8bSHPf25fShQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGuglielmi-tech/Polarity-and-Subjectivity-Detection/blob/main/pre-processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MTL and BERT Embedding"
      ],
      "metadata": {
        "id": "w7wAQxUNIDBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.util import mark_negation\n",
        "from typing import List, Dict\n",
        "\n",
        "def negative_marking(doc : List[str]) -> List[str]:\n",
        "    '''\n",
        "        Params :\n",
        "        -----------------\n",
        "            doc : list[str]\n",
        "                document where each element is a list of strings\n",
        "        Returns :\n",
        "            negated_doc : list[str]\n",
        "                document after having applied double negation\n",
        "    '''\n",
        "\n",
        "    flat_doc = [w for sent in doc for w in sent]\n",
        "    negated_doc = mark_negation(flat_doc, double_neg_flip=True)\n",
        "\n",
        "    return \" \".join([w for w in negated_doc])"
      ],
      "metadata": {
        "id": "Y-l2lJzeIJ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob.en import subjectivity\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import subjectivity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('subjectivity')\n",
        "\n",
        "\n",
        "mr = movie_reviews\n",
        "sub = subjectivity\n",
        "neg = mr.paras(categories='neg')\n",
        "pos = mr.paras(categories='pos')\n",
        "\n",
        "\n",
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]\n",
        "\n",
        "print(len(neg), len(pos))\n",
        "print(len(subj_docs), len(obj_docs))"
      ],
      "metadata": {
        "id": "RgjxowT1INcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_corpus = [negative_marking(d) for d in pos] + [negative_marking(d) for d in neg]"
      ],
      "metadata": {
        "id": "BK2vCXX9IQTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(new_corpus, columns=['text'])"
      ],
      "metadata": {
        "id": "W9E_3PO0ITS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "MAYDVV7gIVTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "from textblob import TextBlob as tb\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "## https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
        "# since re are largely used for this type of applications, the regex module is used\n",
        "# re.sub(pattern, repl, string, count=0, flags=0)\n",
        "\n",
        "def pre_processing(text : str) -> str :\n",
        "  '''Clear text from numbers, stop words (very common words), punctuation and \n",
        "    correct possible misspelled words\n",
        "\n",
        "    Params :\n",
        "    --------\n",
        "      cw : List[str]\n",
        "        list of words in the sentence to be cleaned\n",
        "    Returns :\n",
        "    ---------\n",
        "      list of cleaned words\n",
        "  '''\n",
        "\n",
        "  stop_list = set(stopwords.words(\"english\"))\n",
        "  text = list(text.lower().split())\n",
        "  text = ' '.join([word for word in text if word not in stop_list])\n",
        "  # remove http links\n",
        "  text = re.sub(r'http\\S+', '', text)\n",
        "  # Remove hashtags\n",
        "  text = re.sub(r'#\\w*', '', text)\n",
        "  # Remove whitespace (including new line characters)\n",
        "  text = re.sub(r'\\s\\s+', '', text)\n",
        "  # Remove single space remaining at the front of the tweet.\n",
        "  text = text.lstrip(' ') \n",
        "  # Remove @username\n",
        "  text = re.sub('@[^\\s]+','', text)\n",
        "  text = list(text.translate(str.maketrans('', '', string.punctuation)).split())\n",
        "  # correction of possible miss-click\n",
        "  text = ' '.join([str(tb(word).correct()) for word in text])\n",
        "\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "pre_processing('it is a beautiful lif, https://github @matthew')"
      ],
      "metadata": {
        "id": "no717q1sIZEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].apply(pre_processing)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "HLdREU1AIfFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "G9BH0Cz6IhM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [[1,0]] * len(data['text']//2) + [[0,1]] * len(data['text']//2)\n",
        "len(labels)"
      ],
      "metadata": {
        "id": "d2juMGg5IjXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(labels, columns=['pos', 'neg'])"
      ],
      "metadata": {
        "id": "1lsuLa9AIlpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7xnzDmV1Inb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_data = pd.concat([data, df], axis=1)"
      ],
      "metadata": {
        "id": "0Ze1E13AIp86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}