@misc{kaggle,
  title = {{IMDB Dataset of 50K Movie Reviews}},
  howpublished = {\url{https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews}}
}

@misc{sequence,
  title = {{BertForSequenceClassification}},
  howpublished = {\url{https://huggingface.co/docs/transformers/v4.21.1/en/model_doc/bert#transformers.BertForSequenceClassification}}
}

@misc{model,
  title = {{BertModel}},
  howpublished = {\url{https://huggingface.co/docs/transformers/v4.21.1/en/model_doc/bert#transformers.BertModel}}
}
    
@misc{tokenizer,
  title = {{BertTokenizer}},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer}}
}

@misc{vectorizer,
  title = {{sklearn.feature$\_$extraction.text.CountVectorizer}},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html}}
}


@misc{naive,
  title = {{sklearn.naive$\_$bayes.MultinomialNB}},
  howpublished = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB}}
}

@misc{refe,
    title = {{Large Movie Review Dataset}},
    howpublished={\url{https://ai.stanford.edu/~amaas/data/sentiment/}}
}

@misc{train,
    title = {{Large Movie Review Dataset}},
    howpublished={\url{https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb#scrollTo=YpvnFFmZJD-N}}
}

@online{lab11,
  author = {Evgeny A. Stepanov},
  title = {Sentiment Analysis/Opinion Mining},
  year = {2021},
  month = {Oct},
  howpublished = {\url{https://github.com/esrel/UNITN.NLU.Lab/blob/master/notebooks/11_sentiment_analysis.ipynb}}
}

@misc{wordpiece, 
    author={Yonghui, W. and Schuster, M. and Chen, Z. and V. Le, Q and Norouzi, M. Macherey, W. 
        and Krikun, M. and Cao, Y. and  Gao, Q. and Macherey, Q. and Klingner, J. and Shah, A. and 
        Johnson, M. and Liu, X. and Kaiser, L. and
        Gouws, S. and Kato, Y. and Kudo, T. and Kazawa, H. and Stevens, K. and
        Kurian, G. and Patil, N. and Wang, W. and Young, C. and Smith, J. and Riesa, J. and
        Rudnick, A. and Vinyals, O. and Corrado,G. and Hughes, M. and Dean, J.}, 

    title={Googleâ€™s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}, 
    editor = {arXiv},
    month = {Oct},
    year={2016},
    howpublished = {\url{https://arxiv.org/abs/1609.08144v2}},
    note = {[Online] Submitted on 26 Sep 2016 (v1), last revised 8 Oct 2016 (v2)}
}

@misc{mtl,
    author = {Satapathy, R. and Pardeshi, S.R. and Cambria, E.},
    title = {Polarity and Subjectivity Detection with Multitask Learning and BERT Embedding},
    editor = {Future Internet},
    month = {Jun},
    year = {2022},
    howpublished = {\url{https://doi.org/10.3390/fi14070191}},
    note = {[Online] Submitted: on 6 May 2022/Revised: 8 June 2022/Accepted: 16 June 2022/Published: 22 June 2022}
}

@misc{trainer,
    author = {huggingface.co},
    title = {Trainer},
    howpublished = {\url{https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html}},
}
@misc{bce,
    author = {PyTorch},
    title = {BCELOSS},
    howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html}},
}

@misc{stack,
    author = {{Stack Overflow}},
    title = {What is the loss function used in Trainer from the Transformers library of Hugging Face?},
    howpublished = {\url{https://stackoverflow.com/questions/71581197/what-is-the-loss-function-used-in-trainer-from-the-transformers-library-of-huggi}},
}


@misc{glove,
    author = {{Jeffrey Pennington, Richard Socher, Christopher D. Manning}},
    title = {GloVe: Global Vectors for Word Representation},
    howpublished = {\url{}https://nlp.stanford.edu/projects/glove/},
}


@misc{word2vec,
    author = {{Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean}},
    title = {Efficient Estimation of Word Representations in Vector Space},
    editor = {arXiv},
    month = {Sep},
    year = {2013},
    howpublished = {\url{https://arxiv.org/abs/1301.3781}},
}
