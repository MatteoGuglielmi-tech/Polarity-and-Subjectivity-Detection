% (approx. 200-500 words)

\section{Data description and analysis}
\label{sec:data}
For this project, I've used three different datasets to perform different steps. 
\subsection{Movie reviews dataset}
\label{subsec:mr}
The movie reviews dataset used in this work is directly deployed by the \texttt{nltk.corpus} python package whose characteristics are the following :
\begin{itemize}
    \item number of words : $1583820$;
    \item lexicon size : $39768$;
    \item categories : 'neg', 'pos'.
\end{itemize}
Each movie review has a file id associated with it which is the identification factor of movie review.\\
The dataset presents itself in a peculiar structure. As just mentioned, each review has a specific file asociated to it so in order to ease the following work, everything has been flattened into a single list containing different documents. Each of the list element has an associated label. \\
From an operational perspective, this dataset is used just as an "evaluation set". The motivation behind this is that the total number of reviews (elements in the list) are just $2000$. Since the procedure deployed implies to perform a fine-tuning operation of a Bert transformer model, dividing the already small dataset into train and test sets would result in an insufficient amount of data.\\
For this reason, the whole dataset has been used just to address the final polarity classifiaction accuracy.
\subsection{Subjectivity dataset}
\label{subsec:subj}
As the previously discussed dataset, also in this case the Subjectivity dataset comes from the nltk.corpus python module.\\ 
The main characteristics of this dataset are :
\begin{itemize}
    \item vocabuluary size : $240576$;
    \item lexicon size (without considering repetitions of words) : $23906$;
    \item classes : 'obj', 'subj';
    \item total number of sentences consiering both objective and subjective sentences : $10000$.
\end{itemize}
In this specific case, there are just two unique file ids corresponding to the documentis containing the objective and subjective sentences. The taraget datastructure used consists in the union of those two files.
\subsection{IMDB dataset}
\label{subsec:imdb}
The IMDB Dataset has $50k$ movie reviews for natual language processing or text analytics ~\cite{kaggle}. This dataset can be used for binary sentiment classfication and it provides $25k$ highly polar samples for training and $25k$ samples for testing. More information reguarding this dataset can be found at ~\cite{refe}.
